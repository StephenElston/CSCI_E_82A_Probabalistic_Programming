{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Probabilistic Programming\n",
    "\n",
    "\n",
    "\n",
    "## CSCI E-83\n",
    "## Stephen Elston\n",
    "\n",
    "Real-world machine intelligence and machine learning operates in an uncertain world. Probabilistic programming encompasses a range of algorithms for making decisions and inferences under uncertainty. Probabilistic programming has multiple uses in machine learning and artificial intelligence. Probabilistic programming methods arise in problems in many areas including, scheduling, robotics, natural language processing and image understanding. \n",
    "\n",
    "This course will give you a background in the theory and practice of probabilistic programming, including:\n",
    "1. Develop the ability to apply probabilistic programming methods to machine intelligence and machine learning applications. \n",
    "2. Have an understanding of the theory that connects various probabilistic programming methods. \n",
    "3. Have hands-on experience applying probabilistic programming algorithms to various machine intelligence and machine learning problems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About your teaching  staff\n",
    "\n",
    "**Steve Elston:** \n",
    "\n",
    "\n",
    "\n",
    "**Teaching Fellow:** TBA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent model of machine intelligence\n",
    "\n",
    "A general model for **machine intelligence** or **artificial intelligence** involves an **agent** interacting with the **environment**. The agent uses **sensors** to acquire information on the environment and based on the **state** of the environment takes **actions** to change the state of the environment. A schematic representation of this simple model is shown in Figure 1 below. \n",
    "\n",
    "<img src=\"img/AgentModel.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> **Figure 1. General Agent Model** </center>\n",
    "\n",
    "At the minimum, the agent must have certain capabilities:\n",
    "\n",
    "1. A **Representation** of the model used by the agent to represent the relationships in the model. A good representation is often the key to good machine intelligence. A good representation is a mapping of the model and the environment. Graphical models provide an effective representation for many complex problems. Alternatively, so called **deep representations** produce powerful results in many situations. \n",
    "2. **Inference or reasoning** is the process of computing actions or decisions from **queries** of the model given the **evidence**. In the simplest form a query returns a mathematical result, such as the **marginal probability distribution** or the **maximum a posteriori** value. Reasoning computes a specific action which is applied to the environment. \n",
    "3. The agent performs **learning** using data or **evidence** to update the model. The evidence is observed by **sensors** which provide information to the model on the **state of the environment**. For graphical models, learning involves two distinct steps, learning the the structure of the model and learning parameters of the model. In graphical probabilistic models learning and inference are actually the same process.   \n",
    "\n",
    "A schematic of this simple agent model \n",
    "\n",
    "<img src=\"img/AIModel.JPG\" alt=\"Drawing\" style=\"width:500px; height:250px\"/>\n",
    "<center> **Schematic view of an agent** </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why probabilistic programming?\n",
    "\n",
    "\n",
    "Machine intelligence must operate in a world where: \n",
    "\n",
    "1. Data is often noisy or otherwise **uncertain**. A related problem is the possibility of **unreliable** evidence. Machine learning models must be resistant to unexpected and erroneous sensor inputs. In some cases, the uncertain or unreliable evidence are deliberately produced. This results in what is known as an **adversarial** situation. \n",
    "2. Unexpected situations occur on a regular basis. Often these 'unexpected situations' are simply cases just outside the set of training cases. Many machine learning models produce erroneous or unexpected results when faced with unexpected inputs; a situation known as **brittleness**.    \n",
    "3. Many real-world problems have a high degree of complexity which cannot be feasibly modeled explicitly. \n",
    "4. Models of many real-world systems include **unobservable** variables. There is no feasible way to obtain direct evidence on these variables. \n",
    "5. Optimizing complex processes requires a sequence of decisions. These decisions often must be made with uncertain and incomplete information. \n",
    "\n",
    "Probabilistic models provides a framework for a wide range of difficult problems including:\n",
    "\n",
    "1. Dealing gracefully with unexpected or erroneous inputs. Probabilistic models can exhibit robustness to unexpected inputs as each observation or piece of evidence is probability weighted. \n",
    "2. In many cases, probabilistic models can effectively represent highly complex problems. Conceptually, a probabilistic model 'smooths' over a certain amount of complexity allowing a relatively simple representation of a complex system. \n",
    "3. Inferences can be made on **unobservable** variables with probabilistic models. The **marginal probability distribution** of the unobservable variables can be estimated from the model. This process is known as making a **query** on the model. \n",
    "4. Prior information, such as input on **beliefs** from domain experts, can be used to supplement data or **evidence**. This allows models to work in data poor situations, or for modeling rare events. \n",
    "5. Probabilistic models can operate as **generative models**. A generative model computes new synthetic cases from an original training set. Ideally, the statistics of the generated data are identical to those generated by the real environment. \n",
    "6. The combination of **probabilistic models** and **utility theory** provides a framework for complex decisions under uncertainty. This capability gives [please complete this statement]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "## Decision theory and probability\n",
    "\n",
    "Many AI problems require a decision to be made. In this case the agent makes an inference based on a probabilistic model. Based on this inference a **decision** to take an action is made by finding the maximum **utility** of the alternatives. The agent's decision process is then a combination of probability theory and utility theory. This decision making process is also referred to as **reasoning**.\n",
    "\n",
    "In particular, the combination of probabilistic Markov process and a utility function leads to a **Markov decision process** or **MDP**. The goal of these problems is to maximize the utility of a series of **decisions** in a system with a probabilistic model. \n",
    "\n",
    "In many practical situations multiple decisions must be made in a time sequence. These decisions are made using both uncertain and incomplete information. Optimizing such decisions requires the combination of probabilistic models and utility theory found in MDPs.  \n",
    "\n",
    "In many situations, the variable we wish to control is **unobservable**. For example, we may need to control the torque of a robot's arm motor. The torque is unobservable, but other variables like the voltage on the motor, and dynamical information on the arms position, velocity and acceleration are all observable with sensors. We can model the behavior of the arm as a **partially observable Markov decision process** or **POMDP**.\n",
    "\n",
    "Optimal MDP solutions can be found by a number of algorithms. **Dynamic programming** algorithms are the most widely used methods. However, dynamic programming is limited to cases where a probabilistic model for the system being acted on can be modeled completely. An alternative that has emerged in recent years is **reinforcement learning** which can only requires a **utility function** and does not require an explicit probabilistic model.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning in probabilistic models\n",
    "\n",
    "Learning is at the core of probabilistic models. A variety of machine learning algorithms are available for learning with probabilistic models. In general there is a trade-off between computational complexity and accuracy.      \n",
    "\n",
    "### Learning for graphical models\n",
    "\n",
    "There are two distinct aspects of the specification process of graphical models:\n",
    "\n",
    "1. The **qualitative specification** which defines the skeleton of the of the graphical model. The skeleton specifies the influences of one variable on another. This specification can be created in a number of ways, including elucidation from domain experts, and learning from data. However, as we will see later, learning the qualitative specification from data is not only computationally intensive, but requires a significant amount of data.   \n",
    "2. The **quantitative specification** which defines the details of the conditional distributions. In Bayesian graphical models, the quantitative specification is created using a combination of prior information and evidence. Luckily for us, there are computationally efficient exact and approximate algorithms.     \n",
    "\n",
    "\n",
    "### Learning for reinforcement learning models\n",
    "\n",
    "Reinforcement learning is in a class of algorithms know as **function approximation** methods. These algorithms attempt to learn complex functions to relate data inputs to posterior values or outputs. Inherently, these models have a large number of parameters which must be determined in the training process. \n",
    "\n",
    "Reinforcement learning models are trained using a utility function. It is this utility function which must be approximated. However, the relationship between observable variables and the utility function is complex and inherently nonlinear. \n",
    "\n",
    "As a result of the inherent complexity training reinforcement learning models is both computationally intensive and requires vast amounts of data. These facts limits the problems to which reinforcement learning can be applied. Creating more general algorithms for training reinforcement learning models is an active area of research.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, Stephen F Elston. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
