{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Learning Model Parmaters\n",
    "\n",
    "\n",
    "\n",
    "## CSCI E-83\n",
    "## Stephen Elston\n",
    "\n",
    "\n",
    "In the previous lesson we examined several exact inference methods. When we applied these methods inference methods the parameters of the conditional probability distributions (CPD) were assumed known. But, how do we find these parameters in practice? \n",
    "\n",
    "In this lesson we will focus on the **learning** for Bayesian network models. There are two aspects of learning for Bayesian networks:  \n",
    "1. **Parameter estimation** where the parameters of the CPDs of a model are estimated. We focus on this aspect of the problem in this notebook.   \n",
    "2. **Structure estimation** is the process of estimating the structure of the graphical model. This problem is the subject of another notebook.  \n",
    "\n",
    "The role of learning in an intelligent agent is illustrated in the figure below. For Bayesian models the learning and inference processes often merge as in the case where evidence is applied.  \n",
    "\n",
    "<img src=\"img/Learning.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **Learning in an intelligent agent** </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple parameter estimation example\n",
    "\n",
    "In previous lessons we used a belief network of a student looking for a job. As you will recall the student must submit her GRE score, $S$ and her letter of recommendation, $L$. Said that the probability of the GRE score (high, low) was conditional on the student's intelligence, $I$. We had a prior distribution of $I = [0.8, 0.2] = [p(high), p(low)]$. But, how do we estimate the parameters for this distribution?\n",
    "\n",
    "There are several methods which can be used to estimate the parameters of a distribution including:\n",
    "- Frequentist **maximum likelihood** or **ML** methods which only require that a likelihood function be specified. \n",
    "- Bayesian **maximum a-postiori** or **MAP** methods, which require the specification of both a likelihood function and a prior distribution of the model parameters. \n",
    "\n",
    "In this lesson we will focus on the MAP methods, but will also investigate ML methods. MAP methods are inherently Bayesian and therefore provide a more complete picture of distributions. However, MAP methods can be difficult to implement and computationally intensive. Thus in practice, ML methods are used. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Bernoulli and Beta distributions\n",
    "\n",
    "For this example, we will work with a binary variable with states {0,1}. A **single realization** of such a variable has a **Bernoulli distribution**. The Bernoulli distribution is a **parametric distribution** which we can express as:\n",
    "\n",
    "$$p(\\nu = 1) = \\Theta \\\\\n",
    "where\\\\\n",
    "\\nu = an\\ observation\\\\\n",
    "\\Theta = probability\\ parameter$$\n",
    "\n",
    "For a series of observations of a binary valued variable we use the **Binomial distribution**. We call each observation where $\\nu = 1$ a **success**. The Binomial distribution of $k$ successes in $n$ trials is then expressed as:\n",
    "\n",
    "$$p(\\nu = k\\ |\\ \\Theta) = \\binom{n}{k} \\Theta^k (1-\\Theta)^{n-k}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We want to specify a **Binomial likelihood** in Bayes theorem, we will also need to specify a prior distribution. We pick a prior distribution which is **conjugate** to the likelihood distribution so that the posterior distribution is the same as the prior. We can express this concept as:\n",
    "\n",
    "$$posterior\\_distribution(hypothesis\\ |\\ data) = \\frac{likelihood(data\\ |\\ hypothesis)* conjugate\\_prior(hypothesis)}{marginal\\ distribtion\\ data }\\\\\n",
    "where\\\\\n",
    "posterior\\_distribution\\ is\\ same\\ family\\ as\\ prior\\_distribution$$\n",
    "\n",
    "The question is, which distribution is the conjugate to the Binomial distribution? The answer is the **Beta distribution**. We can express the Beta distribution as: \n",
    "\n",
    "$$p(x\\ |\\ \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}x^{\\alpha - 1}(1-x)^{\\beta - 1},\\ 0 \\le x \\le 1\\\\\n",
    "where\\\\\n",
    "B(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha,\\beta)}\\\\\n",
    "and\\\\\n",
    "\\Gamma(x) = Gamma\\ function$$\n",
    "\n",
    "At first glance, the Beta distribution is a bit complicated. But for the most part the normalization with the Gamma function are not terribly important. \n",
    "\n",
    "You can develop some intuition about the Beta distribution by plotting it for various values of $\\alpha$ and $\\beta$. Execute the code in the cell below and examine the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import scipy.stats as ss\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "alpha = [.5, 1, 2, 3, 4]\n",
    "beta = alpha[:]\n",
    "x = np.linspace(.001, .999, num=100)\n",
    "\n",
    "for i, (a, b) in enumerate(it.product(alpha, beta)):\n",
    "    plt.subplot(len(alpha), len(beta), i+1)\n",
    "    plt.plot(x, ss.beta.pdf(x, a, b))\n",
    "    plt.title('(a,b) = (%d,%d)' % (a,b))\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some points to notice here:\n",
    "\n",
    "- The range is $0 \\le Beta(x) \\le 1$.\n",
    "- If $\\alpha \\gt \\beta$ the distribution is left skewed, if $\\alpha \\lt \\beta$ the distribution is right skewed, and if $\\alpha = \\beta$ the distribution is symmetric.\n",
    "- For $\\alpha = 1$, $\\beta = 1$ the distribution is uniform. \n",
    "\n",
    "With these preliminary in mind, we will now look at methods to estimate the parameter of the Binomial likelihood distribution $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback-Liebler Divergence\n",
    "\n",
    "To train deep learning models **cross entropy** is often used as a loss function. This is an information theoretic measure of model fit. We can understand cross entropy as follows. \n",
    "\n",
    "First define **Shannon entropy** as:\n",
    "\n",
    "$$\\mathbb{H}(I) = E[I(X)] = E[-ln_b(P(X))] = - \\sum_{i=1}^n P(x_i) ln_b(P(x_i))$$  \n",
    "Where:  \n",
    "$E[X] = $ the expectation of $X$.  \n",
    "$I(X) = $ the information content of $X$.   \n",
    "$P(X) = $ probability of $X$.  \n",
    "$b = $ base of the logarithm.    \n",
    "\n",
    "This rather abstract formula gives us a way to compute the expected information content of a set of values $X$. The more likely (higher probability) of $X$ the less informative it is. \n",
    "\n",
    "To create a loss function from the definition of Shannon entropy we start with the **Kullback-Leibler divergence (KL divergence)** or **relative entropy**. The KL divergence is an information theoretic measure of the difference between two distributions, $P(X)$ and $Q(X)$.\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P \\parallel Q) = - \\sum_{i=1}^n p(x_i)\\ ln_b \\frac{p(x_i)}{q(x_i)}$$\n",
    "\n",
    "Ideally, in the case of training a machine learning model we want a distribution $Q(X)$, which is identical to the actual data distribution $P(X)$. \n",
    "\n",
    "But, you may say, if we could know $P(X)$ why compute $Q(X)$ at all? Fortunately, we do not have to. We can rewrite the KL divergence as:\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P \\parallel Q) = \\sum_{i=1}^n p(x_i)\\ ln_b p(x_i) - \\sum_{i=1}^n p(x_i)\\ ln_b q(x_i)$$\n",
    "\n",
    "Since $P(X)$ is fixed and we wish to find $Q(X)$ when we train our model, we can minimize the term on the right, which is the **cross entropy** defined as:\n",
    "\n",
    "$$\\mathbb{H}(P,Q) = - \\sum_{i=1}^n p(x_i)\\ ln_b q(x_i)$$\n",
    "\n",
    "From the formulation of KL divergence above you can see the following.\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P \\parallel Q) = \\mathbb{H}(P) + \\mathbb{H}(P,Q)\\\\\n",
    "\\mathbb{D}_{KL}(P \\parallel Q) = Entropy(P) + Cross\\ Entropy(P,Q)$$\n",
    "\n",
    "Thus, we can minimize divergence by minimizing cross entropy. This idea is both intuitive and computationally attractive. The closer the estimated distribution $q(X)$ is to the distribution of the true underling process $p(X)$, the lower the cross entropy and the lower the KL divergence. \n",
    "\n",
    "In general we will not know $p(X)$. In fact, if we did, why would we need to solve a training problem? So, we can use the following approximation.\n",
    "\n",
    "$$\\mathbb{H}(P,Q) = - \\frac{1}{N} \\sum_{i=1}^n ln_b q(x_i)$$\n",
    "\n",
    "You may notice, that this approximation, using the average log likelihood, is equivalent to a maximum likelihood estimator (MLE). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood with K-L Divergence\n",
    "\n",
    "We wish to find a distribution $q(x)$ with is identical to some unknown, and unknowable, data generating distribution $p^*(x)$. We can use the K-L divergence  \n",
    "\n",
    "$$\\mathbb{D}_{KL}(p^* \\parallel q) = \\sum_{i=1}^n p^*(x_i)\\ ln_b \\frac{p^* (x_i)}{q(x_i)} = \n",
    "- \\mathbb{H}(p^*) - \\mathbb{E}_{x \\sim p^*} [log\\ q(x)]$$\n",
    "\n",
    "The first term only depends on $p^*$ so we do not need to consider this term. The maximum likelihood is achieved by maximizing the expected log-likelihood, $\\mathbb{E}_{x \\sim p^*} [log\\ q(x)]$. This requires that the samples from $p^*$ reflect the true process distribution. Using this approach, we can compare distributions, $q(x)$, but never know if we have found the optimum.   \n",
    "\n",
    "Finding the maximum of $\\mathbb{E}_{x \\sim p^*} [log\\ q(x)]$ is still problematic, since we will never know $p^*$. But, we can use the empirical log-likelihood, for example as using a Monte Carlo estimate. The approach gives the following approximation: \n",
    "\n",
    "$$\\mathbb{E}_{x \\sim p^*} [log\\ q(x)] = \\frac{1}{|D|} \\sum_{x \\in D} log\\ q(x)$$\n",
    "\n",
    "Where, $D$ is the dataset drawn from the generating distribution $p^*$.\n",
    "\n",
    "Given this approximation we can then find the maximum likelihood:\n",
    "\n",
    "$$\\underset{p \\in D}{\\max} \\frac{1}{|D|} \\sum_{x \\in D} log\\ q(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum likelihood method\n",
    "\n",
    "We will not go into the details of **maximum likelihood estimation** (**MLE**). These details can be found in many standard texts on statistics and machine learning including Murphy (Section 7.3), Hastie, Tibshirani and Friedman (Section 2.6), and many others.  \n",
    "\n",
    "\n",
    "Not surprisingly, in order to perform maximum likelihood estimation, we must define a **likelihood function** for the distribution we are trying to estimate. Given data $\\mathcal{V}$ and parameters of the distribution, $\\Theta$, we can express a likelihood function as $\\mathcal{L}(\\Theta, \\mathcal{V}) = p(\\mathcal{V}\\ |\\ \\Theta)$. In most cases, we will work with the **log likelihood**, $log(p(\\mathcal{V}\\ |\\ \\Theta))$. The maximum likelihood estimate or MLE for the parameters is then:\n",
    "\n",
    "$$\\hat{\\Theta} \\doteq argmax_{\\Theta} \\{ \\log(p(\\mathcal{V}\\ |\\ \\Theta)) \\}$$\n",
    "\n",
    "In words, we want to find the parameters which maximize the likelihood of the distribution for the data sample. \n",
    "\n",
    "Let's use computing the maximum likelihood for the Bernoulli distribution as an example. The likelihood function for the Bernoulli distribution is given a data vector $\\mathcal{V}$:\n",
    "\n",
    "$$L(\\Theta) = \\prod_{i=1}^n \\Theta^{\\nu_i}\\ (1-\\Theta)^{(1 - \\nu_i)})$$\n",
    "\n",
    "The log likelihood is easily computed:\n",
    "\n",
    "$$\\log({L}(\\Theta)) = \\log(\\Theta) \\sum_{i=1}^n \\nu_i + \\log(1-\\Theta)  \\sum_{i=1}^n (1 - \\nu_i)$$\n",
    "\n",
    "To find the maximum of this function we must find a point where the first partial derivative is zero:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{l}(\\Theta)}{\\partial \\Theta} = \\frac{\\sum_{i=1}^n \\nu_i}{\\Theta} \n",
    "- \\frac{\\sum_{i=1}^n (1 - \\nu_i)}{1-\\Theta} = 0$$\n",
    "\n",
    "The solution is: \n",
    "\n",
    "$$\\Theta = \\frac{1}{n} \\sum_{i=1}^n \\nu_i$$\n",
    "\n",
    "The simple result is that the maximum likelihood value of $\\Theta$ is just the mean of the data. In simple terms, we can write this relationship:\n",
    "\n",
    "$$\\Theta = \\frac{count\\ of\\ successes}{total\\ count}$$\n",
    "\n",
    "You can verify that the second partial derivative is negative, indicating this is the maximum of the log likelihood function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian learning\n",
    "\n",
    "We can now try the Bayesian approach to estimating the parameter $\\Theta$. Conceptually you can visualize this process as a directed Bayesian model as shown below. \n",
    "\n",
    "<img src=\"img/PlateDiagram.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **Bayes network and plate diagram for parameter estimation** </center>\n",
    "\n",
    "The parameter $\\Theta$ is causal to the vector of data values $\\vec{\\nu} = \\{ \\nu^1, \\nu^2, \\nu^3, \\ldots \\nu^N \\}$. This relationship is shown as a DAG on the left side of the figure above. On the right side of the diagram is a summary using **plate notation**. The plate is short hand for the $N$ values. \n",
    "\n",
    "The unnormalized conditional probability of the parameter $\\Theta$ given the data vector $\\vec{\\nu}$ is: \n",
    "\n",
    "$$p(\\Theta\\ |\\ \\nu^1, \\nu^2, \\nu^3, \\ldots \\nu^N) \\propto p(\\Theta) \\prod_{n=1}^N p(\\nu^n\\ |\\ \\Theta)\n",
    "= \\propto p(\\Theta) \\prod_{n=1}^N \\Theta^{I(\\nu^n=1)}(1 - \\Theta)^{I(\\nu^n=0)}\\\\\n",
    "\\propto p(\\Theta)\\ \\Theta^{\\sum_{n=1}^N I(\\nu^n=1)}(1 - \\Theta)^{\\sum_{n=1}^N I(\\nu^n=0)} $$\n",
    "\n",
    "For a simple binary case of $\\{ True, False \\}$ the solution can be obtained with the prior distribution $p(\\Theta)$ and the counts, $\\{ N_T, N_F \\}$.\n",
    "\n",
    "$$p(\\Theta\\ |\\ \\nu^1, \\nu^2, \\nu^3, \\ldots \\nu^N) \\propto p(\\Theta)\\ \\Theta^{N_T} (1 - \\Theta)^{N_F}$$  \n",
    "Given a data vector, $\\mathcal{V}$, how do we compute the most probable value of $\\Theta$. The solution in this case is relatively easy and can be performed using just counts of the two values, {True, False} or {1,0} and the prior distribution. \n",
    "\n",
    "The likelihood given counts can be expressed as follows.\n",
    "\n",
    "$$\\Theta^{\\mathcal{C}(\\nu_i = 1)} (1-\\Theta)^{\\mathcal{C}(\\nu_i = 0)}\\\\\n",
    "where\\\\\n",
    "\\mathcal{C} = count\\ operator$$\n",
    "\n",
    "Using the above likelihood, the posterior distribution can be expressed as:\n",
    "\n",
    "$$p(\\Theta\\ |\\ \\mathcal{V}) \\propto p(\\Theta)\\ \\Theta^{\\mathcal{C}(\\nu_i = 1)} (1-\\Theta)^{\\mathcal{C}(\\nu_i = 0)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, how do we specify the prior distribution, $P(\\Theta)$? The Beta distribution is the **conjugate** of the Binomial distribution. A the product of a distribution and its conjugate is in the family of the original distribution. Thus, it is both a theoretical and practical nicety to formulate a prior as the conjugate. \n",
    "\n",
    "Recall that the Beta distribution which has two parameters $\\alpha$ and $\\beta$:\n",
    "\n",
    "$$p(x\\ |\\ \\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}x^{\\alpha - 1}(1-x)^{\\beta - 1}$$\n",
    "\n",
    "Given the Beta distribution we can specify the prior distribution in terms of **pseudo counts**. The pseudo count of successes is the value of the parameter $\\alpha$. The pseudo count of failures is the value of the parameter $\\beta$. \n",
    "\n",
    "Using the Beta prior, the posterior distribution of the can be written:\n",
    "\n",
    "$$p(\\Theta\\ |\\ \\nu^1, \\nu^2, \\nu^3, \\ldots \\nu^N) \n",
    "\\propto  \\Theta^{\\big( \\sum_{n=1}^N I(\\nu^n=1) \\big)\\ + \\alpha }(1 - \\Theta)^{\\big( \\sum_{n=1}^N I(\\nu^n=0) \\big)\\ + \\beta } $$\n",
    "\n",
    "As with the maximum likelihood solution we can find the **maximum a posteriori (MAP)** value of $\\Theta$ as:\n",
    "\n",
    "$$\\Theta = \\frac{count\\ of\\ successes + \\alpha}{total\\ count + \\alpha + \\beta}$$\n",
    "\n",
    "Some properties of the posterior given the Beta prior distributed prior include:\n",
    "- The higher the ratio $\\frac{\\alpha}{\\beta}$ the larger the prior value of $\\Theta$.\n",
    "- The larger the sum of $\\alpha$ and $Beta$ the stronger the prior. Small values of $\\alpha$ and $Beta$ specify a vague prior. \n",
    "- The larger the actual counts, the less important the prior is in determining $\\Theta$.\n",
    "- If $\\alpha = \\beta = 0$ the Bayesian estimate of $\\Theta$ is identical to the maximum likelihood estimate. \n",
    "- If there are no actual counts, the estimate of $\\Theta$ is the prior. \n",
    "- The prior regularizes the estimation of Q, even for variables with no observations.\n",
    "\n",
    "Further details can be found in Murphy, Section 3.3 or Barber, Section 9.4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Example\n",
    "\n",
    "Now, its time to put all this theory into practice with a computational example. We will continue to work with the student example illustrated below:\n",
    "\n",
    "<img src=\"img/LetterDAG.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **DAG CPDs for student example** </center>\n",
    "\n",
    "In this example we will perform the following:\n",
    "\n",
    "1. Simulate data for the CPDs of the model.\n",
    "2. Test the CDPs by estimating the parameters using both maximum likelihood and maximum a posteriori methods.\n",
    "3. Estimate the parameters for the entire model using both MLE and MAP methods. We will be able to examine the effects of different prior distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of CPDs\n",
    "\n",
    "Creating, testing and debugging simulation software can be tricky. This is particularly the case when conditional distributions are required. Fortunately, this process is greatly simplified through the use of a DAGs.   \n",
    "\n",
    "Like many other probabilistic graphical model packages pgmpy has a simulation capability. Given a DAG model of class BayesianModel, the `BayesianModelSampling` class computes random samples. The code in the cell below reads a picked model file and computes simulated data from the distribution represented by the model.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate the binary tables\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "import pickle\n",
    "\n",
    "## Load the model from a file\n",
    "with open('student_model.pickle', 'rb') as pkl:\n",
    "    murder_model = pickle.load(pkl)\n",
    "print('The model loaded correctly: {}'.format(murder_model.check_model()))\n",
    "\n",
    "## Simulate values from the DAG\n",
    "def simulate_from_DAG(model, nsamps = 25, set_seed = 234):\n",
    "    nr.seed(set_seed)\n",
    "    simulation = BayesianModelSampling(model)\n",
    "    return(simulation.forward_sample(size = nsamps, return_type='dataframe'))\n",
    "\n",
    "samples_25 = simulate_from_DAG(murder_model)\n",
    "samples_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of above simulation looks reasonable. \n",
    "\n",
    "### MLE\n",
    "\n",
    "But, what happens when we try to estimate the parameters of the distribution? The code in the cell below does the following:\n",
    "\n",
    "1. Constructs a DAG with a single node.\n",
    "2. Performs MLE for the model parameters and displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = BayesianModel()\n",
    "test_model.add_node('D')\n",
    "\n",
    "# Fitting the data to the model using Maximum Likelihood Estimator\n",
    "test_model.fit(pd.DataFrame(samples_25.loc[:,'D']), estimator=MaximumLikelihoodEstimator)\n",
    "print(test_model.get_cpds('D'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLE of the parameters are close to, but not exactly the same as, the value we used for the simulation, [0.1, 0.9]. \n",
    "\n",
    "### MAP\n",
    "\n",
    "Next, we will try a Bayesian estimator. A Dirichlet distribution is used as the prior. We will examine the properties of this distribution in more detail shortly. \n",
    "\n",
    "The prior of a Dirichlet distribution is specified as a set of **pseudo counts**. As with any Bayesian estimation problem, we must face the issue of specification of the prior distribution. For this example, we could use any one, or perhaps a combination of the following approaches:\n",
    "1. Select pseudo counts from previous data sets for the same or similar problems. \n",
    "2. Apply expert judgment. \n",
    "3. Use an uninformative prior, such as a uniform distribution, in which case the pseudo counts are equal. \n",
    "\n",
    "The code in the cell below uses the last approach, a uniform distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data to the model using Maximum Likelihood Estimator\n",
    "pseudo_counts = {'D': [[4], [6]]}\n",
    "test_model.fit(pd.DataFrame(samples_25.loc[:,'D']), estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "print(test_model.get_cpds('D'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAP estimate of parameters are close to know values and considerably different from the prior. This is expected since the sum of the pseudo counts sum to significantly less than the 25 data points. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global and Local Parameter Independence\n",
    "\n",
    "In the foregoing we have only considered the univariate Binomial and Beta distributions. But, real-world problems have many parameters. We need a way to deal with this situation without the mathematical and computational complexity of the full multivariate problem. \n",
    "\n",
    "Our approach is to factorize the joint distribution to introduce **global independence** and **local independence**. The global independence assumption allows us to factorize the **posterior distribution** over the conditional tables. The local independence assumption allows us to factor the prior distribution, a necessary condition for the global independence assumption. \n",
    "\n",
    "### Global independence assumption\n",
    "\n",
    "Let's start with the global independence assumption using an example. Recalling the student example of previous lessons, let's consider the parameterized joint distribution of the student's grade in the machine learning course. Using plate notation we call illustrate this part of the DAG as shown here.\n",
    "\n",
    "<img src=\"img/Factorizing.JPG\" alt=\"Drawing\" style=\"width:200px; height:300px\"/>\n",
    "<center> Plate diagram for factorizing joint distribution $p(\\Theta_D, \\Theta_I, \\Theta_G)$ </center>\n",
    "\n",
    "Let's assume we can factorize the joint distribution as follows.\n",
    "\n",
    "$$p(\\Theta_D, \\Theta_I, \\Theta_G) = p(\\Theta_D)p(\\Theta_I)p(\\Theta_G)$$\n",
    "\n",
    "Were $\\Theta_D$, $\\Theta_I$, and $\\Theta_G$ are parameters of the distributions of difficulty, intelligence and grade respectively. \n",
    "\n",
    "If we assume the table (vector) of N data values, $\\mathcal{X}$, are i.i.d. we can expand the above as:\n",
    "\n",
    "$$p(\\Theta_D, \\Theta_I, \\Theta_G) = p(\\Theta_D)p(\\Theta_I)p(\\Theta_G) \\prod_{n=1}^N p(d^n\\ |\\ \\Theta_D)p(i^n\\ |\\ \\Theta_I)p(g^n\\ |\\ d^n, i^n, \\Theta_G)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local parameter independence\n",
    "\n",
    "The local independence assumption allows us to factorize the prior distribution. Let's say that difficulty, $D$, and intelligence $I$, are only binomially distributed. We can factorize the prior distribution. For example: \n",
    "\n",
    "$$p(\\Theta_G) = p(\\Theta_G)^{0,0}p(\\Theta_G)^{0,1}p(\\Theta_G)^{1,0}p(\\Theta_G)^{1,1}$$\n",
    "\n",
    "Given this factorization we can find a factorization of the posterior distribution. \n",
    "\n",
    "$$p(\\Theta_G\\ |\\ \\mathcal{X}) \\propto p(\\mathcal{X}\\ |\\ \\Theta_G) p(\\Theta_G)^{0,0}p(\\Theta_G)^{0,1}p(\\Theta_G)^{1,0}p(\\Theta_G)^{1,1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Categorical and Dirichlet Distributions\n",
    "\n",
    "Many problems have multiple states or categories. The probabilities of the classes or categories are modeled with the **categorical distribution**. The categorical distribution is the multi-class generalization of the Bernoulli distribution. In fact, this distribution is sometime referred to as the **multinoulli distribution**. For Bayesian learning in these cases, the prior and posterior are modeled with the **Dirichlet distribution**. \n",
    "\n",
    "### The Categorical Distribution\n",
    "\n",
    "We can express the **probability mass** function of the categorical distribution, with $k$ categories, with probability $p_i$ for the ith category as follows.\n",
    "\n",
    "$$f(x = i\\ |\\ \\boldsymbol{p}) = p_i \\\\\n",
    "where\\\\\n",
    "\\boldsymbol{p} = (p_1, \\ldots, p_k),\\ and\\\\ \\sum_{i=1}^k p_i = 1.0$$\n",
    "\n",
    "An alternative formulation uses **Iverson bracket notation**. In this formulation $[x = i] = 1$ and $0$ otherwise. Using this notation the density function of the categorical distribution can be written:\n",
    "\n",
    "$$f(x = i\\ |\\ \\boldsymbol{p}) = \\prod_{i=1}^k p_i^{[x = i]}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dirichlet Distribution\n",
    "\n",
    "In order to perform Bayesian learning with the categorical distribution we need to use Dirichlet distribution as a prior. However, it can be a bit difficult to develop intuition around the behavior of the Dirichlet distribution. We can express the Dirichlet distribution with $n$ categories as follows.\n",
    "\n",
    "$$f(x_1, x_2, \\ldots, x_n; \\alpha_1, \\alpha_2, \\ldots, \\alpha_n) = \\frac{1}{B(\\alpha)} \\prod_{i=1}^{n} x_i^{\\alpha_i - 1}$$\n",
    "Where the normalization is the **Beta function**:\n",
    "$$B(\\alpha) = \\frac{\\prod_{i=1}^{n} \\Gamma (\\alpha_i) }{ \\sum_{i=1}^{n} \\Gamma ( \\alpha_i )}$$\n",
    "And $\\Gamma( x )$ is the Gamma function. \n",
    "\n",
    "For our case of interest, the probabilities of the categories are represented by $\\{ x_1, x_2, \\ldots, x_n \\}$ and are constrained by:    \n",
    "\n",
    "\\begin{align}\n",
    "\\sum_{i=1}^{n} x_i &= 1\\\\ \n",
    "x_i &\\ge 0\n",
    "\\end{align}\n",
    "\n",
    "In fact, in classification problems there is only one category per case, so $[x_i = 1]$ only for the ith category.  \n",
    "\n",
    "The **concentration parameters** $\\{ \\alpha_1, \\alpha_2, \\ldots, \\alpha_n \\}$, determines how *concentrated* the the distribution is for each class. For the Dirichlet distribution, **prior information** is expressed in terms of the concentration hyperparamters $\\boldsymbol{\\alpha} = \\{ \\alpha_1, \\alpha_2, \\ldots, \\alpha_n \\}$. The values of $\\alpha_i$ are parameterized in terms of **pseudocounts** for each category. The pseudocounts express prior information in two ways:\n",
    "- Categories with larger pseudocounts have higher prior probabilities. \n",
    "- The total sum of pseudocounts expresses the strength of the prior. If the sum of all pseudocounts is relatively large with respect to the number of actual data, the prior will be strong.\n",
    "- If all $\\alpha_i$ are equal the Dirichlet distribution is uniform in the probabilities of the classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Parameter Estimation\n",
    "\n",
    "When computing the Bayesian MAP of $\\boldsymbol{p} = (p_1, \\ldots, p_k)$ the posterior is Dirichlet distributed. We will skip the considerable amount of algebra and just state that for a category, $i$, with $c_i$ counts out of $N$ total data or count values values, $\\boldsymbol{X} = (c_1, c_2, \\ldots, c_n)$, the expected posterior MAP of $p_i$ can be expressed:\n",
    "\n",
    "$$E(p_i\\ |\\ \\boldsymbol{X}, \\boldsymbol{\\alpha}) = \\frac{c_i + \\alpha_i}{N + \\sum_k \\alpha_k}$$\n",
    "\n",
    "The above expression has an intuitive explanation. Consider the following:\n",
    "- The probability of a category $i$ increases as the count, $c_i$, increases relative to $N$, the sum of the counts for all categories. \n",
    "- As N increases relative to $\\sum_k \\alpha_k$ the data comes dominate the prior. On the other hand, if there are few actual data the prior will dominate. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimation\n",
    "\n",
    "Computing the MLE for the categorical distribution is rather strait forward. The expression is the same as for MAP, but with all $\\alpha_i = 0$:\n",
    "\n",
    "$$E(p_i\\ |\\ \\boldsymbol{X}) = \\frac{c_i}{N}$$\n",
    "\n",
    "In other words, MLE probability for each category is just the faction of counts for that category in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Parameters for a Full Model\n",
    "\n",
    "We can simultaneously estimate the parameters for an entire model. There are a total of 26 model parameters which must be fit using the 25 data points. Not only, but the distribution of the cases are not uniform given the sampling. This model is seriously **under-determined**. This situation will expose one of the significant weaknesses of MLE.    \n",
    "\n",
    "The code in the cell below performs the following steps for the MLE of the model parameters:\n",
    "1. The structure of the DAG was defined.\n",
    "2. The parameters of the model are estimated using the `MaximumLikelihoodEstimator` in the `fit` method. \n",
    "3. The parameters of the CDPs are printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "\n",
    "student_model = BayesianModel([('D', 'G'), ('I', 'G'), ('G', 'L'), ('I', 'S')])\n",
    "\n",
    "# Learing CPDs using Maximum Likelihood Estimators\n",
    "student_model.fit(samples_25, estimator=MaximumLikelihoodEstimator)\n",
    "for cpd in student_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimates of the conditionally independent variables are mostly as expected. Some of the other CDPs look a bit odd. Notice the 0s in the G, L and S variables. It is possible that much of this behavior is attributable to the under-determined nature of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Estimation\n",
    "\n",
    "Next, we will turn our attention to Bayesian parameter estimation. Recall that we performed Bayesian MAP estimation on the variable D using pseudo counts of $\\{4, 6 \\}$, a uniform and modestly strong prior.   \n",
    "\n",
    "Let's explore the effect of using different priors. In the cell below, the parameters of the variable D are estimated using a strong prior, with pseudo counts $\\{ 50, 50 \\}$. This is considered a strong prior since the pseudo counts are larger than the total number of data cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = BayesianModel()\n",
    "test_model.add_node('D')\n",
    "\n",
    "# Fitting the data to the model using Bayesian Estimator\n",
    "pseudo_counts = {'D': [[50], [50]]}\n",
    "test_model.fit(samples_25, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "print(test_model.get_cpds('D'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the strong prior, the parameter estimates are close to the proportion of the pseudo counts. That is close to the prior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try the parameters ................**************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = BayesianModel([('D', 'G'), ('I', 'G'), ('G', 'L'), ('I', 'S')])\n",
    "\n",
    "# Learing CPDs using Bayesian Estimators\n",
    "pseudo_counts = {'D': [[4], [6]], 'I':[[4],[6]], 'G':[[5,2,8,3],[5,5,5,5],[5,8,2,7]], 'S':[[6,4],[4,6]], 'L':[[7,5,3],[3,5,7]]}\n",
    "student_model.fit(samples_25, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "for cpd in student_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the following:\n",
    "- The parameters of the conditionally independent variables, D and I, are nearly the same as obtained with the MLE method.  \n",
    "- The parameter estimates for the variable G now seem more as we might expect. \n",
    "- The parameter estimates for the variables L and S appear to reflect the prior values of the parameters. \n",
    "\n",
    "The stabilization of the parameter estimates for the variable G is an example of **Bayesian regularization**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLE with more data\n",
    "\n",
    "You may wonder if simply acquiring more data might help the MLE method behave better. In other words, is the small number of cases the only reason for poor MLE performance. Let's explore this aspect of the problem by simulating 10 times as much data. The code in the cell below simulates 250 cases using the same probabilities as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try a larger sample!\n",
    "nsamps = 250\n",
    "samples_250 = simulate_from_DAG(murder_model, nsamps = nsamps)\n",
    "samples_250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will compute the parameters for a model using the 250 data cases using MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.fit(samples_250, estimator=MaximumLikelihoodEstimator)\n",
    "for cpd in student_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.fit(samples_250, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "for cpd in student_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are not much different from the ones obtained with 25 cases in the dataset. Evidently, lack of data was not the key problem. Rather, the structure of the model could be the limitation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, 2019, Stephen F Elston. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_CPDS(model, decimals = 2):\n",
    "    for CPT in student_model.cpds:\n",
    "        print(CPT.variable)\n",
    "        print(np.around(CPT.values, decimals=decimals))\n",
    "        \n",
    "print_CPDS(student_model)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.cpds[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
