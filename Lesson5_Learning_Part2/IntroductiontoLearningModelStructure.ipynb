{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Learning Model Structure\n",
    "\n",
    "\n",
    "\n",
    "## CSCI E-83\n",
    "## Stephen Elston\n",
    "\n",
    "\n",
    "In the previous lesson we explored some approaches to learning model parameters. This discussion assumed that the model structure or skeleton was known. However, there are many cases where this structure may not be known a priori. In this lesson we will focus on algorithms for **learning model structure**. The role of learning in an intelligent agent is illustrated in the figure below.\n",
    "\n",
    "<img src=\"img/Learning.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **Learning in an intelligent agent** </center>\n",
    "\n",
    "The goal of probabilistic network structure learning is to determine the independencies in the distribution of the data. The independencies determine the structure of the graph. Typically the goal is to minimize a measure of **divergence** between the distribution of the data and the distribution represented by the graph.  \n",
    "\n",
    "All methods for learning the structure of probabilistic graphical models are approximate and computationally intensive. At best, the learned structure is an approximation of the  Further, these algorithms require considerably more data than is required for inference. \n",
    "\n",
    "Some options for learning model structure include:\n",
    "\n",
    "- **Eliciting knowledge** from experts on the independencies of the distribution. However, this can be a tedious process for more than fairly simple problems. \n",
    "- Estimate the potentials of the graph though parameter estimation or **parameter learning** of the distributions. This approach assumes that we know these distributions. \n",
    "- Use learning to the structure of the graph, known as **structure learning**. As you will see, this approach will typically lead to an approximate solution, which may not capture the true independencies. \n",
    "\n",
    "Suggested readings for this lesson include the following, along with references contained herein:\n",
    "- Barber Section 9.5,\n",
    "- Murphy Section 26.1, 26.2, 26.3, 26.4. \n",
    "\n",
    "> **Note 1:** In this lesson we are only concerned with finding the structure of Bayesian networks or DAGS. Finding the structure of undirected Markov networks involves maximum likelihood methods, and can be considerably more difficult. For introductions to this problem see Barber Section 9.6 or Murphy Section 26.7. \n",
    "\n",
    "> **Note 2:** In this lesson we will only explore algorithms for finding structure of Bayesian or directed networks with complete data. We will not address the problems of finding the structure of networks with hidden or latent variables. These later problems are considerably harder to deal with and an area of on-going research. **Structural expectation-maximization** or **Structural EM** algorithms are typically used. For an overview of these methods see Murphy Section 26.5 or Barber Section 11.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems of Structure Estimation\n",
    "\n",
    "Finding graphical model the structure from data is a complex problem. The goal is to find a graph structure which best represents the independencies of the distribution of the data. This is accomplished by searching through possible graph structures. \n",
    "\n",
    "Finding graph structure can be used as a data mining method. However, searching for graph structure is not without some serious pitfalls. The result is that any structure determined from a finite quantity of data is approximate at best. Interpretation of any relationships found in resulting graph structures should be done with caution. \n",
    "\n",
    "The pitfalls not withstanding, an approximately correct graph can provide useful inferences for many types of complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Computational Complexity\n",
    "Let's explore the computational complexity of finding the structure of a graphical models. Consider the fully connected graph of the variables in the student model illustrated below.   \n",
    "\n",
    "<img src=\"img/FullyConneted.JPG\" alt=\"Drawing\" style=\"width:400px; height:250px\"/>\n",
    "<center> **Fully connected student graph** </center>\n",
    "\n",
    "There are quite a few possible edges between these variables. Consider the complexity of an algorithm that attempts to search all possible graphs for these variables. The complexity of this type of **exhaustive serach**:\n",
    "\n",
    "$$C(n) = n^{O(2^{O(n)})}$$\n",
    "\n",
    "You can see from the above relationship that exhaustive search is computationally infeasible for all but the smallest graph. This fact means that all practical structure finding algorithms are necessarily approximate.  \n",
    "\n",
    "In practice, structure search is performed using some combination of the following:\n",
    "1. **Constraints** on the search. A common constraint is on the number of parents of each node. Another common constraint is to assume the graph is a tree.\n",
    "2. Use of **search heuristics** to reduce the complexity of the search. There are many possibilities, several of which are used in other machine intelligence applications.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-equivalence and Ambiguity in Graph Structure Search\n",
    "\n",
    "In previous lessons we have seen that the graphs representing an I-map of a distribution are not unique. From another perspective, we can say that it is possible for several DAGs to exhibit Markov equivalence. These facts mean that there is ambiguity in the determination of graph structure from data. It should not come as a surprise that several DASs exhibit nearly the same fit to a set of data.  \n",
    "\n",
    "A further, and often more significant problem in practice,  is that with limited amounts of data determination of independencies is error prone. In fact, it will often be the case that any pair of variables in a finite size dataset will show some dependencies. \n",
    "\n",
    "The above problems can be overcome in an approximate sense in several ways including:\n",
    "- Using constraints on the graph structure search. \n",
    "- Setting thresholds or using significance tests for determining independencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Algorithm\n",
    "\n",
    "One of the oldest algorithms for finding network structure is the **PC algorithm**. The PC algorithm is a locally greedy search algorithm for determining the structure of Bayesian networks. The PC algorithm is a two step process:\n",
    "\n",
    "- The skeleton of the graph is determined.\n",
    "- The direction of the edges is determined.\n",
    "\n",
    "The PC algorithm uses **constraint satisfaction search** methods. Constraint satisfaction search is a classic artificial intelligence learning method. The constraint satisfaction search problem predates the computer era. Frances Guthrie applied the method to the 4 color map problem in 1852. Constraint satisfaction search methods were applied in artificial intelligence starting in the early 1960s. For readable discussion of the constraint satisfaction search methods in artificial intelligence see Chapter 6 of Russell and Norvig, third edition. \n",
    "\n",
    "The determination of the skeleton can be done in a number of ways. One approach is using greedy elimination:\n",
    "\n",
    "- Start with a fully connected network. \n",
    "- Find the a connection with $x \\bot y\\ |\\ \\oslash$ using a **mutual information criteria**. That is $x$ and $y$ are independent. A Chi Squared significance test is used to determine set a cut-off for independence.\n",
    "- Repeat the above step until the algorithm terminates when the number of connections per node is at or below a predetermined threshold. \n",
    "\n",
    "With the skeleton determined, the directions of the edges must be determined. For three variables $x$, $y$ and $z$ this can be done using the independencies:\n",
    "\n",
    "$$x \\bot y\\ |\\ \\oslash \\Rightarrow x\\ y\\ are\\ parents\\ of\\ z$$\n",
    "\n",
    "or  \n",
    "\n",
    "$$x \\bot y\\ |\\ z \\Rightarrow z\\ is\\ parent\\ of x\\ and\\ y$$\n",
    "\n",
    "In practice, the PC algorithm is mostly of historical interest and has inferior performance to newer algorithms.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climb Search\n",
    "\n",
    "A commonly used search method is **hill climbing**, also known as the **method of steepest ascent**. Hill climbing is applied in a number of  There are a number of variations. In general, this search method is a **locally greedy** approach to improving an **objective function**, $f(x)$. \n",
    "\n",
    "To determine the structure of graphical models, the objective function is some measure of the **divergence** between the distribution of the data and the distribution represented by the graph. Finding graph structure is a search of discrete states. These states correspond to the presence or absence of edges between the nodes.    \n",
    "\n",
    "The hill climb search proceeds through a series of discrete states to find the terminal state. The search continues until the improvement in the objective function is less than some threshold. There are several commonly used variants to find the locally greedy improvement including:\n",
    "1. The closest state which improves the objective function is taken as the next step.  \n",
    "2. The successor state with the largest possible improvement is taken at each step.   \n",
    "\n",
    "As with all locally greedy methods, hill climb search can become stuck at **local optimum**. Some more sophisticated variations use stochastic sampling methods to try to overcome this problem. \n",
    "\n",
    "Additional details on the hill climbing algorithm can be found in Section 4.1.1 of Russell and Norvig, third edition. \n",
    "\n",
    "> **Note:** Another commonly used search method is taboo search. This algorithm was developed by Fred Glover in the late 1980s as a mixed integer programming method. For many, but not all, problems taboo search can outperform hill climbing. Taboo search keeps a list of already visited states and prevents the algorithm from revisiting these states. Further, taboo search will accept moves that decrease the objective function if all other states are blocked. In this way, taboo search promotes **exploration** of the space. However, maintaining the taboo list can require prohibitive amounts of memory. You can find a readable introduction to this algorithm in [the Wikipedia article](https://en.wikipedia.org/wiki/Tabu_search)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Scoring and the Bayesian Information Criteria\n",
    "\n",
    "Having discussed the general approach to searching for Bayesian graph structure, let's look at a specific example of scoring a model. We can compute a score for a graph, $\\mathcal{G}$ given data $D$, in a general form: \n",
    "\n",
    "\n",
    "$$Score(\\mathcal{G}:D) = log \\big(\\mathcal{L}(\\mathcal{G}:D) \\big) - \\phi( n ) \\parallel \\mathcal{G} \\parallel$$  \n",
    "Where,       \n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\mathcal{G}:D) &= likelihood\\ given\\ the\\ fitted\\ graph\\ parameters\\\\\n",
    "n &= number\\ of\\ samples\\\\\n",
    "\\parallel \\mathcal{G} \\parallel &= number\\ of\\ parameters\\ in\\ \\mathcal{G}\n",
    "\\end{align}\n",
    "\n",
    "The **Baysian Information Criteria** or **BIC** is a widely used scoring function. It is closely related to the Akaike Information Criteria (AIC). The BIC was proposed by Gideon Schwarz in 1978, and is sometimes referred to as the Schwarz Information Criteria. The . We can write the BIC in the form above as:\n",
    "\n",
    "$$BIC = ln(n) \\parallel G \\parallel- 2\\ ln \\big (\\mathcal{L}(\\mathcal{G}:D) \\big)\n",
    "$$\n",
    "Where,  \n",
    "\\begin{align}\n",
    "\\mathcal{L} &= likelihood\\ given\\ the\\ fitted\\ graph\\ parameters\\\\\n",
    "D &= observed\\ data\\\\\n",
    "\\parallel \\mathcal{G} \\parallel &= number\\ of\\ model\\ parameters\\\\\n",
    "n &= number\\ of\\ observations\n",
    "\\end{align}\n",
    "\n",
    "A few comments on BIC:\n",
    "- The higher the likelihood, the lower the BIC. Models with lower BIC are considered better. \n",
    "- The larger the number of parameters the higher the BIC. Thus, BIC penalizes complex models and prefers simple models with few edges.  \n",
    "\n",
    "BIC is used a model scoring method in conjunction with a search method. For example, the BIC can be used as an objective function for determining if an edge should or should not be in the graph. Strictly speaking, the negative of the BIC is used with the hill climbing algorithm. \n",
    "\n",
    "> **Note:** Despite its name the Bayesian Information Criteria is in no way Bayesian. There is no prior distribution. Further, the result is a score, which cannot be interpreted as a probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Computational Example\n",
    "\n",
    "Having discussed the theory of finding graph structure by model scoring, let's try a computational example. We will continue to work with the student example illustrated below:\n",
    "\n",
    "<img src=\"img/LetterDAG.JPG\" alt=\"Drawing\" style=\"width:400px; height:200px\"/>\n",
    "<center> **DAG CPDs for student example** </center>\n",
    "\n",
    "In this example we will perform the following:\n",
    "\n",
    "1. Simulate data for the CPDs of the model.\n",
    "2. Find the BIC score using the structure used for the simulation.\n",
    "3. Estimate the graph structure.\n",
    "4. Compare the BIC score for the computed graph structure to the BIC score of the structure used for the simulation. \n",
    "\n",
    "Execute the code in the cell below to create 250 cases of simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate the binary tables\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "import pickle\n",
    "\n",
    "## Load the model from a file\n",
    "with open('student_model.pickle', 'rb') as pkl:\n",
    "    murder_model = pickle.load(pkl)\n",
    "print('The model loaded correctly: {}'.format(murder_model.check_model()))\n",
    "\n",
    "## Simulate values from the DAG\n",
    "def simulate_from_DAG(model, nsamps = 25, set_seed = 234):\n",
    "    nr.seed(set_seed)\n",
    "    simulation = BayesianModelSampling(model)\n",
    "    return(simulation.forward_sample(size = nsamps, return_type='dataframe'))\n",
    "\n",
    "nr.seed(4455)\n",
    "nsamps = 250\n",
    "samples_1000 = simulate_from_DAG(murder_model, nsamps = nsamps)\n",
    "samples_1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data simulated, we can create a DAG using the known structure and compute the BIC score. Execute the code in the cell below and note the BIC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore, K2Score, StructureScore\n",
    "from pgmpy.models import BayesianModel\n",
    "\n",
    "model_1 = BayesianModel([('D','G'), ('I','S'), ('I','G'),('G','L')])\n",
    "print(BicScore(samples_1000).score(model_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below uses hill climbing search with the BIC score as the objective function to estimate the skeleton of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_bic = HillClimbSearch(samples_1000, scoring_method=BicScore(samples_1000))\n",
    "bic_model = est_bic.estimate()\n",
    "sorted(bic_model.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below estimates the structure of the belief network. The search is constrained so that a node may have no more than two edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_edges = est_bic.estimate(max_indegree=2).edges()\n",
    "BIC_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure discovered is a simple linear graph. This result is not exactly what might be expected. This structure can be tested by computing the BIC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianModel()\n",
    "model_2 = BayesianModel(BIC_edges)\n",
    "print(BicScore(samples_1000).score(model_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the BIC score has increased considerably from the graph structure used to simulate the dataset. \n",
    "\n",
    "As has been mentioned, a considerable amount of data can be required to find the structure of graphical models. Let's see if this makes a difference. The code in the cell below creates a new dateset with 25,000 simulated cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamps = 25000\n",
    "\n",
    "## First the conditionally independent variables\n",
    "nr.seed(22234)\n",
    "samples_25000 = simulate_from_DAG(murder_model, nsamps = nsamps)\n",
    "samples_25000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data simulated, execute the code in the cell below to define and fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_bic_big = HillClimbSearch(samples_25000, scoring_method=BicScore(samples_25000))\n",
    "bic_model_big = est_bic_big.estimate()\n",
    "print(sorted(bic_model_big.nodes()))\n",
    "bic_edges_big = est_bic_big.estimate(max_indegree=2).edges()\n",
    "bic_edges_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that a more complex tree has been computed as a model. The relationships are quite different from the ones used for the simulation. \n",
    "\n",
    "Now, we can compare the change in BIC from the initial model to the model discovered with the BIC objective function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BicScore(samples_25000).score(model_1))\n",
    "print(BicScore(samples_25000).score(bic_model_big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BIC has changed significantly between the two models. \n",
    "\n",
    "Finally, let's have a look at the independencies for this graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_model_big.local_independencies(['D', 'I', 'S', 'G', 'L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these independencies are different from the model used to simulate the data, they are not unreasonable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The K2 Score method\n",
    "\n",
    "Another approach to model scoring is the **K2 algorithm** or **K2 score method**. The K2 algorithm uses a greedy search, such as hill climbing, and proceeds by the following steps:   \n",
    "1. The nodes are ordered. The search will follow this ordering.   \n",
    "2. The search begins begins with the first node in the order, which initially has no parents.   \n",
    "3. Parents are added incrementally in the order that the action increases the score the most.  \n",
    "4. The search terminates when the score no longer increases. \n",
    "\n",
    "A number of scoring metrics have been used with the K2 algorithm. The most commonly used is the **Bayesian score**. For a graph, $\\mathcal{G}$, and $n$ dimensional data $D$ sampled from the joint distribution we can apply Bayes' theorem:\n",
    "\n",
    "$$p(D\\ |\\ \\mathcal{G}) = \\frac{p(\\mathcal{G}\\ |\\ D) p(\\mathcal{G})}{p(D)} = \\frac{p(\\mathcal{G}, D)}{p(D)}$$\n",
    "\n",
    "The prior distribution, is typically a uniform Dirichlet, unless we have some reason to bias the solution toward a particular structure. \n",
    "\n",
    "Since $p(D)$ is the same for all graph structures we can use either the marginal likelihood, $p(\\mathcal{G}\\ |\\ D)$, or the joint posterior probability distribution.\n",
    "\n",
    "We can assume the parameters associated with each variable in the graph are independent, the K2 metric can be decomposed:\n",
    "\n",
    "$$p(\\mathcal{G}, D) = p(\\mathcal{G}) \\prod_{i=1}^n g(d_i, \\mathbf{P_{a_i}})\\\\ \n",
    "where\\\\\n",
    "g(d_i, \\mathbf{P_{a_i}}) = subscore\\ of\\ ith\\ dimension$$\n",
    "\n",
    "This decomposition allows the search algorithm to find the maximum score variable by variable. \n",
    "\n",
    "The requirement to select a good search order of the nodes can lead to difficulties applying the K2 algorithm in practice. A number of random starts can be used to used to try different node orderings. \n",
    "\n",
    "An advantage of the K2 method is that no restrictions need be applied to the number of parents of a node. The constraints for the search arise from the initial node ordering. \n",
    "\n",
    "A more complete discussion of the K2 algorithm can be found in the [paper by Lerner and Malka](http://www.ee.bgu.ac.il/~boaz/LernerMalkaAAI2011.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Computational Example\n",
    "\n",
    "Let's apply the K2 algorithm to the student model example. \n",
    "\n",
    "As a first step, we can compute the K2 score for the model used for the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K2Score(samples_1000).score(model_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the graph structure using the dataset and the K2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(1234)\n",
    "est_K2S = HillClimbSearch(samples_1000, scoring_method=K2Score(samples_1000))\n",
    "K2S_model = est_K2S.estimate()\n",
    "print(sorted(K2S_model.nodes()))\n",
    "est_K2S_edges = est_K2S.estimate(max_indegree=2).edges()\n",
    "est_K2S_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is different than the ones we obtained using the BIC score. In either case, the result is clearly different from the model used for the simulation.\n",
    "\n",
    "Next we can compute the BIC score for the resulting model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = BayesianModel(est_K2S_edges)\n",
    "print(BicScore(samples_1000).score(model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BIC score has changed a bit with this new model.\n",
    "\n",
    "Let's see if using a larger dataset has any effect. The code in the cell below computes a graph using 25,000 cases rather than 250. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_K2S_big = HillClimbSearch(samples_25000, scoring_method=K2Score(samples_25000))\n",
    "K2S_model_big = est_K2S_big.estimate()\n",
    "print(sorted(K2S_model_big.nodes()))\n",
    "est_K2S_big.estimate(max_indegree=2).edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting graph structure is the same as the one obtained by using fewer cases. \n",
    "\n",
    "But how does the K2 score change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K2Score(samples_25000).score(model_1))\n",
    "print(K2Score(samples_25000).score(K2S_model_big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences in K2 score are larger, indicating we can be more certain about this model structure. \n",
    "\n",
    "What are the independencies in this DAG? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K2S_model_big.local_independencies(['D', 'I', 'S', 'G', 'L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These independencies are noticeably different from those obtained using the BIC score. \n",
    "\n",
    "Finally, we can compare the model obtained with BIC scoring to the model using K2 scoring. We can use both K2 and BIC score for this comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K2Score(samples_25000).score(bic_model_big))\n",
    "print(K2Score(samples_25000).score(K2S_model_big))\n",
    "print(BicScore(samples_25000).score(bic_model_big))\n",
    "print(BicScore(samples_25000).score(K2S_model_big))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the K2 scores of the two different models are identical. The BIC score of the model created with BIC scoring is a bit better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of Information Theory\n",
    "\n",
    "In order to find an optimal structure for a Bayesian directed graphical model we need to have a loss **loss function**, also known as a **cost function**. In simple terms, the loss function measures how well the graphical model represents the available data. The lower the loss, the better the fit. \n",
    "\n",
    "### Shannon Entropy\n",
    "\n",
    "As a first step in understanding information theory we need to define **Shannon entropy**:\n",
    "\n",
    "$$\\mathbb{H}(I) = E[I(X)] = E[-ln_b(P(X))] = - \\sum_{i=1}^n P(x_i) ln_b(P(x_i)$$  \n",
    "Where:  \n",
    "$E[X] = $ the expectation of $X$.  \n",
    "$I(X) = $ the information content of $X$.   \n",
    "$P(X) = $ probability of $X$.  \n",
    "$b = $ base of the logarithm.    \n",
    "\n",
    "This rather abstract formula gives us a way to compute the expected information content of a vector of observations $X$. The more likely (higher probability) $X$ is the less informative it is. In other words, unexpected observations carry the most information.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullback-Leibler Divergence\n",
    "\n",
    "To create a loss function from the definition of Shannon entropy we start with the **Kullback-Leibler divergence (KL divergence)** or **relative entropy**. The KL divergence is an information theoretic measure of the difference between two distributions, $P(X)$ and $Q(X)$.\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P|Q) = - \\sum_{i=1}^n p(x_i)\\ ln_b \\frac{p(x_i)}{q(x_i)}$$\n",
    "\n",
    "Ideally, in the case of training a machine learning model we want a distribution $Q(X)$, which is identical to the actual data distribution $P(X)$. In this case the KL divergence is 0 since:\n",
    "\n",
    "$$ln (\\frac{p(x_i)}{q(x_i)}) = ln(1) = 0$$\n",
    "\n",
    "But, you may say, if we could know $P(X)$ why compute $Q(X)$ at all? Fortunately, we do not have to. We can rewrite the KL divergence as:\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P|Q) = \\sum_{i=1}^n p(x_i)\\ ln_b \\big(p(x_i) \\big) - \\sum_{i=1}^n p(x_i)\\ ln_b \\big( q(x_i) \\big)$$\n",
    "\n",
    "Here, $ln_b$ is the log base 2 logarithm. Using base 2 gives KL divergence units of bits. \n",
    "\n",
    "Since $P(X)$ is fixed and we wish to find $Q(X)$ when we train our model, we can minimize the term on the right, which is the **cross entropy** defined as:\n",
    "\n",
    "$$\\mathbb{H}(P,Q) = - \\sum_{i=1}^n p(x_i)\\ ln_b q(x_i)$$\n",
    "\n",
    "From the formulation of KL divergence above you can see the following.\n",
    "\n",
    "$$\\mathbb{D}_{KL}(P|Q) = \\mathbb{H}(P) + \\mathbb{H}(P,Q)\\\\\n",
    "\\mathbb{D}_{KL}(P|Q) = Entropy(P) + Cross\\ Entropy(P,Q)$$\n",
    "\n",
    "Thus, we can minimize divergence by minimizing cross entropy. This idea is both intuitive and computationally attractive. The closer the estimated distribution $q(X)$ is to the distribution of the true underling process $p(X)$, the lower the cross entropy and the lower the KL divergence. \n",
    "\n",
    "In general we will not know $p(X)$. In fact, if we did, why would we need to solve a training problem? So, we can use the following approximation.\n",
    "\n",
    "$$\\mathbb{H}(P,Q) = - \\frac{1}{N} \\sum_{i=1}^n ln_b q(x_i)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "\n",
    "There is one other information theoretic concept we must address, **mutual information**. Conceptually, mutual information between two variables measures how much knowing the value of one variable tells us about the other. Quantitatively, we can express mutual information as follows:\n",
    "\n",
    "$$I(X;Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x,y) log \\Big( \\frac{p(x,y)}{p(x) p(y)} \\Big)$$ \n",
    "\n",
    "We can gain some intuition by considering the value of $I(X;Y)$ when the two distributions are independently distributed. In this case:\n",
    "\n",
    "$$log \\Big( \\frac{p(x,y)}{p(x) p(y)} \\Big) = log(1) = 0$$\n",
    "\n",
    "In words, when $p(x)$ and $p(y)$ are independent there is no mutual information. \n",
    "\n",
    "Mutual information has several important properties. The first property is that mutual information must be greater than or equal to zero; $I(X;Y) \\ge 0$. Second, mutual information is symmetric: $I(X;Y) = I(Y;X)$. We can also relate mutual information to entropy, conditional entropy and joint entropy as follows:\n",
    "\n",
    "$$I(X;Y) \\equiv H(X) - H(X\\ |\\ Y) \\equiv H(Y) - H(Y\\ |\\ X) \\\\\n",
    "\\equiv H(X) + H(Y) - H(X,Y)$$\n",
    "\n",
    "Finally, the mutual information, $I(X;Y)$, is the Kullback-Leibler divergence between the product of $p(x)$ and $p(y)$ and the joint distribution $p(x,y)$: \n",
    "\n",
    "$$I(X;Y) = D_{KL}\\big( p(x,y) \\parallel p(x)\\ p(y) \\big)$$\n",
    "\n",
    "Intuitively, the greater this divergence the more information available on one variable given the other. Likewise, if $p(x)$ and $p(y)$ are independent the KL divergence with respect to the joint distribution is 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Chow-Liu Tree Algorithm\n",
    "\n",
    "The Chow-Liu algorithm is an information theoretic approach to finding the structure of probabilistic models. The idea is to find a tree structure for the graph that best fits the distribution as measured by the KL divergence. The Chow-Liu tree algorithm has some practical advantages over many heuristic methods, since it is guaranteed to converge. \n",
    "\n",
    "The KL divergence for a DAG with a distribution, $q(x)$, representing an unknown distribution, $p(x)$, with $D$ variables,becomes:\n",
    "\n",
    "$$KL(p  \\parallel q) = \\mathbb{E}_{p(x)} \\big( log(p(x)) \\big) - \\sum_{i=1}^D \\mathbb{E}_{p(x_i,x_{pa(i)})}  \\big(   \n",
    "log(q(x_i\\ |\\ x_{pa(i)}) \\big)$$  \n",
    "where, $\\mathbb{E}$ indicates the expectation over the distribution. \n",
    "\n",
    "The for any two variables in the distribution, $x_i$ and $x_j$  mutual information is:\n",
    "\n",
    "$$MI(x_i, x_j) = \\mathbb{E}_{p(x)} \\bigg( log \\Big( \\frac{p(x_i,p_j)}{p(x_i)\\ p(x_j)} \\Big) \\bigg)$$\n",
    "\n",
    "After some considerable algebra (see Section in Barber 9.5.4 and many other sources for details) we can now write the KL divergence of the tree as:\n",
    "\n",
    "$$KL(p  \\parallel q) = -\\sum_{i=1}^D MI(x_i;x_{pa(i)})- \\mathbb{E}_{p(x_i)}\n",
    "\\big( log(p(x_i)) \\big) + Constant$$\n",
    "\n",
    "The second term depends only on $p(x)$ and the third term is a constant. Thus minimizing $KL(p  \\parallel q)$ is the same as maximizing $\\sum_{i=1}^D MI(x_i;x_{pa(i)})$.  \n",
    "\n",
    "Maximizing the mutual information seems like a straight forward approach to finding graphical model structure. However, this problem is under-constrained. For finite sized datasets, the mutual information between any pair of variables in unlikely to be $0$. \n",
    "\n",
    "Unfortunately, the Chow-Liu tree algorithm is not implemented in the pgmpy package. If you want to try a Python API for Chow-Liu trees look into the well tested [Pomegranate package](https://pomegranate.readthedocs.io/en/latest/). Pomegranate contains a number of other interesting algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, 2019, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
