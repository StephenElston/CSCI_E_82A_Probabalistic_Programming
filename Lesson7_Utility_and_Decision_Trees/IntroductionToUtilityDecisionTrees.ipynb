{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Utility and Influence Diagrams\n",
    "\n",
    "## CSCI E-82A\n",
    "### Stephen Elston\n",
    "\n",
    "In this lesson we will start our study of **planning methods**. By planning we mean methods an **agent** which uses a **model of the environment** to find an **optimal sequence of decisions** when faced with **uncertain**.  \n",
    "\n",
    "A number of planning methods have been developed, starting in the 1940's. These early planning theories were intended to optimize the production and use of industrial resources during the Second World War.\n",
    "\n",
    "In this lesson we will use an extended version of the probabilistic graph theory we have been studying compute optimal decision. Specifically, we will focus on the following topics:\n",
    "\n",
    "1. **Utility theory:** which allows us to **quantify the value of a system state**. \n",
    "2. **Influence diagrams:** which are an extension of the **representation** we have used for Bayesian graphical models. \n",
    "3. **Inference:** to compute the **sequence of optimal decisions**. \n",
    "\n",
    "**Suggested readings:** The following reading is an optional supplement to the material presented here:\n",
    "- Barber, Sections 7.1, 7.2, 7.3, 7.4, or\n",
    "- Russell and Norvig, third edition, Chapter 16, or\n",
    "- Kochenderfer, Sections 3.1 and 3.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planning, Agents and the Environment\n",
    "\n",
    "A schematic diagram of our planning **agent** and its interaction with the **environment** is shown in the figure below. \n",
    "\n",
    "<img src=\"img/AgentEnvironment.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> **Interaction of agent and environment** </center>\n",
    "\n",
    "This model of the interaction shown between the intelligent agent and the environment applies to a number of machine intelligence situations. There are three points of interaction between the agent and the environment. This separation between the intelligent agent and the environment is defined by these interactions.\n",
    "\n",
    "1. The **state** of the environment is **observed** by the agent. The **sensors** used to observe state are part of the environment and not the agent. \n",
    "2. A method by which the agent can cause **actions** in the environment. The actuators which carry out the agent's commands are part of the environment and not the agent. \n",
    "3. Rewards provide the agent **feedback** on the **value** or **utility** of the state of the environment. The reward is generated in the environment and not the agent. \n",
    "\n",
    "Notice that there is strict division between the agent and the environment. The agent provides the intelligence. All other activities occur in the environment. This division is necessary so that intelligence is separate from any activity in the environment. \n",
    "\n",
    "Consider an example of an intelligence agent, your prefrontal cortex, and your environment. In this case you must perform a number of task to start at home, perform your job, get paid, your reward, and return home. This plan requires a great number of interactions with the environment and decisions including:\n",
    "\n",
    "1. Your prefontal cortex must decide when to leave. This agent commands some actuators, fingers, to tap your phone and your sensors, optic nerves, observe the bus schedule. Based on past experience, the agent knows there is a high probability the bus will run late. To avoid the negative reward of arriving late an earlier bus is chosen. \n",
    "2. As you leave the house, the agent uses actuators of the hands and fingers and sensors, the optic nerves to ensure you have your keys. \n",
    "3. Many more steps involve getting to work. Another set of tasks are required to perform your job, perhaps eat some lunch with a friend, and return home. \n",
    "4. Ultimately, your prefrntal cortex uses sensors and actuators to examine a bank account and see the change of state when you get paid. \n",
    "\n",
    "In the above scenario notice that the performs no action and collects no state information. Rather, this agent controls the actuators and uses sensors to find the state of the environment and receive the reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Utility Theory\n",
    "\n",
    "To make optimal decisions an intelligent agent must have a way to measure the value of the outcomes. Creating functions to measure the value of outcomes is the domain of **utility theory**. \n",
    "\n",
    "Let's think about a simple example. Let's say that you go to a charity dinner and you buy a raffle ticket to win a prize worth \\$1,000. There are 100 tickets and each ticket costs $100. Your joy of supporting this important charity is worth 200 to you. What is your utility of buying one ticket:\n",
    "\n",
    "$$U(1) = -p(buy) * cost + p(feeling) * value + p(win) * 1000 \\\\\n",
    "= - 1.0 * 100 + 1.0 * 200 + 0.01 * 1000 \\\\\n",
    "= 110$$\n",
    "\n",
    "From the foregoing example you can likely see that the general form of a utility function can be expressed:\n",
    "\n",
    "$$U(S) = \\sum_{s} p(s)\\ u(s)\\\\\n",
    "where\\\\\n",
    "p(s) = probability\\ of\\ state\\ s\\\\\n",
    "u(s) = utility\\ of\\ state\\ s $$\n",
    "\n",
    "Let's continue with the example. There is no reason that a utility function should have linear scaling. To understand this consider what your utility will be if you buy two raffle tickets. Your cost is now $200 for the tickets, and you have doubled your chance of winning the prize. You might think that your utility might be only 20. But, perhaps not. Your joy at helping the charity might be 400 making your utility of your larger donation: \n",
    "\n",
    "$$U(2) = - 1.0 * 2 * 100 + 1.0 * 400 + 0.01 * 2 * 1000 \\\\\n",
    "= 220$$\n",
    "\n",
    "From the above, you can see that **amount of money does not equal utility**. To understand this concept consider the following situation. In his youth, your instructor took many long backpacking trips. The person who organized the food for one 5-day hike did a poor job. Meals were minimal, and by the last day, there was no food left at all. We arrived in Aspen Colorado in mid afternoon quite hungry. We found a popular hamburger restaurant and spent the very last bit of money to buy a hamburger. The utility of that hamburger was much greater than the price paid. Then as now, Aspen is a playground of the wealthy. It is very likely that the utility of a hamburger to these wealthy customers was considerably less than too a young man who has not had enough to eat for several days!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions and Expected Utility\n",
    "\n",
    "By itself, a utility function does not tell us anything about the results of **actions** the agent might take. The **expected utility function** is the product of the value of a state multiplied by the probability of being in a state given the observation and the action:\n",
    "\n",
    "\n",
    "$$E \\big[ U(a\\ |\\ o) \\big] = \\sum_{s'} p(s'\\ |\\ a,o)\\ U(s') $$\n",
    "\n",
    "For a planning problem we want to find the **optimal action**, $a$, such that:\n",
    "\n",
    "$$argmax_a E \\big[ U(a\\ |\\ o) \\big] = argmax_a \\sum_{s'} p(s'\\ |\\ a,o)\\ U(s') $$\n",
    "\n",
    "While simple conceptually, directly applying the above formulation to solve for the optimal action can be difficult beyond the simplest problems. An example of such a problem can be represented as a **decision tree**, which allows relatively direct solution. However, using this representation is limited both by intellectual capacity and computational complexity. We will not go further down this path. You can see some more detail along with some examples in Section 7.2 in Barber. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence Diagram\n",
    "\n",
    "In previous lessons we have investigated the use of Bayesian networks as a representation of probability distributions and their independencies. We can extend this representation to become **influence diagrams**.   \n",
    "\n",
    "A representation for a decision process must preserve **causality**. A decision cannot be made until previous decisions have been made and resulting state is observed. Bayesian networks represent causality or influence of one set of variables to others. \n",
    "\n",
    "There are two additional elements that must be added to Bayesian networks to transform them to influence diagrams:\n",
    "1. Decision nodes which have no distribution. In effect, the decision nodes are like switches which initiate actions in the environment. We illustrate decisions nodes as rectangles. \n",
    "2. Utility nodes, which measures the value of the states of the environment. We illustrate utility nodes as diamonds. \n",
    "\n",
    "We also need three types of directed edges to specify influence diagrams. \n",
    "- Edges that **propagate belief**, or conditional information as we used before. \n",
    "- **Informational edges** which propagate information that is not related to a distribution or belief.\n",
    "- **Functional edges** which end in utility nodes which propagate the information needed for the utility calculation. \n",
    "\n",
    "Let's look at a few simple cases that occur in influence diagrams. As illustrated in the diagram below a random variable in an influence diagram can be dependent on both other random variables as well as decisions. We have already spent considerable time on dependencies and independencies of random variables. But consider what happens when a decision is imposed. The decision will force the probabilities of some states to 0. That is, a decision allows some states but not others to occur. \n",
    "\n",
    "<img src=\"img/RandomVariable.JPG\" alt=\"Drawing\" style=\"width:300px; height:100px\"/>\n",
    "<center> **Dependent random variable with decision** </center>\n",
    "\n",
    "In the above diagram notice that the edge between the decision and the random variable is shown as an **information link**. This is because, decisions have no distributions associated with them. \n",
    "\n",
    "The diagram below shows how a utility node can be dependent on both random variables and decision nodes. We have already discussed how a probability distribution is used to compute utility. A decision will fix the set of states which are possible and therefore the total utility. \n",
    "\n",
    "<img src=\"img/Utility.JPG\" alt=\"Drawing\" style=\"width:300px; height:100px\"/>\n",
    "<center> **Utility with decision and random variable** </center>\n",
    "\n",
    "In the above case, the diagram contains two function edges, one with distribution information and the other with decision information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency and Partial Ordering\n",
    "\n",
    "As has already been mentioned causality is important in influence diagrams. This property is know as **causal consistency**. Influence in must be in causal order. This organization is called **partial ordering**. \n",
    "\n",
    "Let's say that we have a series of variables, $\\chi_i$, separated by decision variables, $D_i$. The variable $\\chi_i$ must be observed before the decision $D_i$ can be made. The variable $\\chi_{i+1}$ cannot be observed before decision $D_i$ is made. We represent the partial ordering with the precedence symbol, $\\prec$. We represent this situation as:\n",
    "\n",
    "$$\\chi_1 \\prec D_1 \\prec \\chi_2 \\prec D_2 \\ldots \\chi_n \\prec D_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Influence Diagrams\n",
    "\n",
    "In previous lessons, we explored a number of widely used exact inference methods for Bayesian belief networks. It turns out that many of the inference methods for Bayesian networks, like variable elimination, belief propagation, and the junction tree algorithm, can be applied to the case of influence diagrams as well. \n",
    "\n",
    "Here, we will only touch on the variable elimination method. Variable elimination for influence diagrams follows a similar process as for Bayesian networks. The difference being that we proceed in the reverse of the partial ordering.   \n",
    "\n",
    "Given the partial ordering of a set of random variables $x_t$ and decision variables $d_t$ we can write the probability of the $T$th state:\n",
    "\n",
    "$$p(x_{1:T}, d_{1:T}) = \\prod_{t = 1}^T p(x_t\\ |\\ x_{t-1}, d_{1:t})$$\n",
    "\n",
    "Multiplying through by the utility, $u(x_{1:T}, d_{1:T})$ we can maximize the sums over the variables for each of the decisions:  \n",
    "\n",
    "$$max_{d_1} \\sum_{x_1} \\cdots max_{d_{T}} \\sum_{x_{T}} \\prod_{t = 1}^T p(x_t\\ |\\ x_{t-1}, d_{1:t})\\ u(x_{1:T}, d_{1:T})$$\n",
    "\n",
    "We can rearrange the sums so that we can eliminate variables, resulting in a new marginal utility variable, $\\widetilde{u}(x_{1:T-1}, d_{1:T-1})$:\n",
    "\n",
    "$$ max_{d_1} \\sum_{x_1} \\cdots max_{d_{T-1}} \\sum_{x_{T-1}} \\prod_{t = 1}^{T-1} p(x_t\\ |\\ x_{t-1}, d_{1:t})\\ max_{d_{T}} \\sum_{x_{T}} p(x_T\\ |\\ x_{1:T-1}, d_{1:T}) u(x_{1:T}, d_{1:T}) \\\\\n",
    "= max_{d_1} \\sum_{x_1} \\cdots max_{d_{T-1}} \\sum_{x_{T-1}} \\prod_{t = 1}^{T-1} p(x_t\\ |\\ x_{t-1}, d_{1:t})\\ \\widetilde{u}(x_{1:T-1}, d_{1:T-1})$$\n",
    "\n",
    "There is one factorization we can apply to variable elimination on influence diagrams to simplify the problem. We can take advantage of the fact that early decisions are **independent** of latter decisions since the later decisions are not yet known. Thus, in many cases we can simply sum the marginal utilities.\n",
    "\n",
    "> **Note:** You can find some more information on how to apply belief propagation and the junction tree algorithm influence diagrams in sections 7.4.1 and 7.4.2 or Barber. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Computational Example. \n",
    "\n",
    "Let's work though a computational example to make these concepts more concrete. Consider a delivery robot which must make decisions under uncertainty. The robot is required to make on-time deliveries or a credit must be given to the customer to compensate for the late arrival of the order. The utility for the robot is:\n",
    "\n",
    "| On time | Slightly late | Very late|\n",
    "|-----|----|----|\n",
    "|25|0.5|-25|\n",
    "\n",
    "The influence diagram for the delivery robot's intended trip is shown in the figure below:\n",
    "\n",
    "<img src=\"img/Bridge.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> **Influence Diagram for the Delivery Robot** </center>\n",
    "\n",
    "The partial ordering of this problem is:\n",
    "\n",
    "$$leave\\ early \\prec U1 \\prec P(traffic\\ delay\\ |\\ traffic) \\prec take\\ bridge \\prec p(bridge\\ delay\\ |\\ bridge\\ open) \\prec U2$$\n",
    "\n",
    "The Utility for arrival times, U2, has already been stated. \n",
    "\n",
    "In this simple example, there are two decisions:\n",
    "1. The robot must determine if it should leave early or not. Leaving early, has lower utility since the robot is not available to perform other deliveries. \n",
    "2. Toward the end of its journey, the robot must decide to take a direct route over a draw bridge or a longer route with no bridge. However, with some nonzero probability the bridge may open for an extended period of time to allow marine traffic to pass. Notice that this decision is dependent on how early or late the robot is at the decision time. \n",
    "\n",
    "The expected arrivals for the robot give the delay at the bridge decision time. There are six possible cases for the three states of arrival time. The first two cases, correspond to the decision to take the alternate route. The other 4 cases are conditionally dependent on the state of the bridge. The CPD looks like this:\n",
    "\n",
    "| Arrival |  alternate route, no traffic delay | alternate route, traffic delay | bridge closed - no traffic delay | bridge closed- traffic delay | bridge open - no traffic delay | bridge open - traffic delay |   \n",
    "|----|----|----|----|----|----|----|----|\n",
    "| on time | 0.6 | 0.5 | 0.90 | 0.6 | 0.0 | 0.00 |\n",
    "| slightly late | 0.3 | 0.3 | 0.05 | 0.2 | 0.05 | 0.05 |  \n",
    "| very late | 0.1 | 0.2 | 0.05 | 0.2 | 0.95 | 0.95 |\n",
    "\n",
    "If the decision is made to avoid the bridge, the state of the bridge does not matter. Therefore we assign a probability of 1.0 to no bridge delay in these cases. The bridge is open about 10% of the time, so the CPD for the bridge looks like this:\n",
    "\n",
    "|  | alternate route, no traffic delay | alternate route, traffic delay | bridge closed - no traffic delay | bridge closed- traffic delay | bridge open - no traffic delay | bridge open - traffic delay |   \n",
    "|----|----|----|----|----|----|----|----|\n",
    "| P(closed) | 1.0 | 1.0 | 0.9 | 0.9 | 0.1 | 0.1 |\n",
    "\n",
    "Now we have all the information we need to perform the first set of variable eliminations. The variable include:\n",
    "- The decision to take the bridge.\n",
    "- The CPD of no delay given the state of the bridge, the decision to take the bridge and if the robot is late at the decision time. \n",
    "- The probability the bridge is closed - no delay. \n",
    "- The utility for arrival time states. \n",
    "\n",
    "The variable elimination will reduce these variables to the marginal utility for the best cases of arriving late at the decision point or not. The code comments in the cell below explain the details of the calculation. \n",
    "\n",
    "> **Note** The code in this example is intended for illustration purposes rather than production performance and quality. Apply this approach at your own risk! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of delay by routes\n",
      "[[0.6   0.5   0.81  0.54  0.    0.   ]\n",
      " [0.3   0.3   0.045 0.18  0.005 0.005]\n",
      " [0.1   0.2   0.045 0.18  0.095 0.095]]\n",
      "\n",
      "Utilities by routes and delay\n",
      "[[ 1.500e+01  1.250e+01  2.025e+01  1.350e+01  0.000e+00  0.000e+00]\n",
      " [ 1.500e-01  1.500e-01  2.250e-02  9.000e-02  2.500e-03  2.500e-03]\n",
      " [-2.500e+00 -5.000e+00 -1.125e+00 -4.500e+00 -2.375e+00 -2.375e+00]]\n",
      "\n",
      "The marginal utility for by route and early or late at decsion point\n",
      "[12.65    7.65   19.1475  9.09   -2.3725 -2.3725]\n",
      "\n",
      "Maximum utiltiies for on time and late at decision point\n",
      "[19.1475  9.09  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "## payoff for on-time, slightly late, and very late delivery\n",
    "U2 = [25, 0.5, -25] \n",
    "## Probability of arrival time\n",
    "## Three rows = on time, slighly late, very late\n",
    "delay2 = np.array([[0.6, 0.5, 0.90, 0.6, 0.0, 0.00],\n",
    "                   [0.3, 0.3, 0.05, 0.2, 0.05, 0.05],\n",
    "                   [0.1, 0.2, 0.05, 0.2, 0.95, 0.95]])\n",
    "## Probability bridge is open\n",
    "bridge_up = np.array([1.0, 1.0, 0.9, 0.9, 0.1, 0.1])\n",
    "\n",
    "## Compute probability of arrival times given bridge \n",
    "bridge_delay = np.multiply(delay2, bridge_up)\n",
    "print('Probabilities of delay by routes')\n",
    "print(bridge_delay)\n",
    "\n",
    "## Compute utility\n",
    "print('\\nUtilities by routes and delay')\n",
    "bridge_utility = np.transpose(np.multiply(np.transpose(bridge_delay), U2))\n",
    "print(bridge_utility)\n",
    "\n",
    "## Marginal utilities for the 6 cases.\n",
    "marginal_bridge_utility = np.sum(bridge_utility, axis = 0)\n",
    "print('\\nThe marginal utility for by route and early or late at decsion point')\n",
    "print(marginal_bridge_utility)\n",
    "\n",
    "## Now we need the maximum utility of leaving on time and delayed arrival at the decison point. \n",
    "## The first number in the array is the utility or \n",
    "max_bridge_utility = np.array([np.max(marginal_bridge_utility[[0,2,4]]), np.max(marginal_bridge_utility[[1,3,5]])])\n",
    "print('\\nMaximum utiltiies for on time and late at decision point')\n",
    "print(max_bridge_utility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two utility values are the maximum for early and late arrival at the bridge decision point. In the first case, the maximum utility is to take the bridge. However, if the robot arrives late at the decision point the maximum utility is to take the alternate route. \n",
    "\n",
    "We are ready for the second variable elimination. In this case we want to compute the marginal utility of leaving early or not. The variables to be eliminated are:\n",
    "\n",
    "- The decision to leave early.\n",
    "- The CPD of traffic delay given the decision to leave early or not.\n",
    "- The probability of heavy traffic.\n",
    "\n",
    "We want to compute the marginal probability of early and late arrival at the bridge for two possible decisions, leaving early or leaving on time.\n",
    "\n",
    "The CPD of arriving at the bridge decision point early or late is:    \n",
    "\n",
    "|  | leave early, light traffic | leave on time, light traffic |  leave early, heavy traffic | leave on time, heavy traffic |\n",
    "|----|----|----|----|----|\n",
    "|Arrive early | 0.8 | 0.7 | 0.6 | 0.3 |\n",
    "|Arrive late | 0.2 | 0.3 | 0.4 | 0.7 |\n",
    "\n",
    "The probability distribution of light and heavy traffic is:    \n",
    "\n",
    "| | leave early, light traffic | leave on time, light traffic |  leave early, heavy traffic | leave on time, heavy traffic |\n",
    "|----|----|----|----|----|\n",
    "|p(traffic) | 0.3 | 0.3 | 0.2 | 0.2 |\n",
    "\n",
    "The comments in the code cell below explain the details of the variable elimination process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of arrival by traffic delay\n",
      "[[0.8 0.7 0.6 0.3]\n",
      " [0.2 0.3 0.4 0.7]]\n",
      "\n",
      "Probabilities of arrivals given traffic\n",
      "[[0.24 0.21 0.12 0.06]\n",
      " [0.06 0.09 0.08 0.14]]\n",
      "\n",
      "Marginal probability of early or late at bridge decsion for early leaving\n",
      "[0.45 0.15]\n",
      "\n",
      "Marginal probability of early or late at bridge decsion for on time leaving\n",
      "[0.18 0.22]\n"
     ]
    }
   ],
   "source": [
    "## probability of high trafic\n",
    "trafic = np.array([0.3, 0.3, 0.2, 0.2])\n",
    "## Probability of arrival by tranfic\n",
    "traffic_delay = np.array([[0.8, 0.7, 0.6, 0.3],\n",
    "                          [0.2, 0.3, 0.4, 0.7]])\n",
    "print('Probabilities of arrival by traffic delay')\n",
    "print(traffic_delay)\n",
    "\n",
    "## Compute probabilities of arrivals \n",
    "traffic_arrivals = np.multiply(traffic_delay, trafic)\n",
    "print('\\nProbabilities of arrivals given traffic')\n",
    "print(traffic_arrivals)\n",
    "\n",
    "## Compute marginal probability of early or late at bridge decsion\n",
    "prob_early = np.sum(traffic_arrivals[:,:2], axis = 1)\n",
    "print('\\nMarginal probability of early or late at bridge decsion for early leaving')\n",
    "print(prob_early)\n",
    "\n",
    "## Compute marginal probability of early or late at bridge decsion\n",
    "prob_on_time = np.sum(traffic_arrivals[:,2:], axis = 1)\n",
    "print('\\nMarginal probability of early or late at bridge decsion for on time leaving')\n",
    "print(prob_on_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to put this all together. We have the marginal distributions of the arrival at the bridge decision point for early and on time leaving. We also have the the marginal utility for the choice or bridge or the alternative.\n",
    "\n",
    "We can take advantage of the fact that the utility of time of leaving is independent of arrival at the customer. Thus, we can compute the total utility for both possibilities and find the maximum. \n",
    "\n",
    "The utility of leaving early has the following table: \n",
    "\n",
    "| | leave early | leave on time |\n",
    "|----|----|\n",
    "|Utility | -5 | 0 |\n",
    "\n",
    "The details of the calculation are outlined in the comments in the code cell below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected utility for early leaving\n",
      "[3.616375 1.3635  ]\n",
      "\n",
      "Total utility for early leaving\n",
      "4.979875\n",
      "\n",
      "Expected utility for leaving on time\n",
      "[3.44655 1.9998 ]\n",
      "\n",
      "Total utility for on time leaving\n",
      "5.446350000000001\n"
     ]
    }
   ],
   "source": [
    "## Utility of leaving early or on time\n",
    "U1 = [-5.0, 0] \n",
    "\n",
    "## Let's put this all together \n",
    "## Compute the overall utilities based on probability of on time\n",
    "overall_utility = np.multiply(max_bridge_utility, prob_early) + U1\n",
    "print('Expected utility for early leaving')\n",
    "print(overall_utility)\n",
    "print('\\nTotal utility for early leaving')\n",
    "print(np.sum(overall_utility))\n",
    "\n",
    "## Compute the overall utilities based on probability of on time\n",
    "overall_utility = np.multiply(max_bridge_utility, prob_on_time) \n",
    "print('\\nExpected utility for leaving on time')\n",
    "print(overall_utility)\n",
    "print('\\nTotal utility for on time leaving')\n",
    "print(np.sum(overall_utility))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the delivery robot should start early and take the bridge to achieve the maximum expected utility. However, if the robot finds itself running late, the alternative route will maximize utility. \n",
    "\n",
    "But, what would change if the bridge had a toll? The toll would reduce the expected utility of the bridge route. But, if the toll is 2 or less, the bridge would still be the better route if the robot not running late. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2018, Stephen F Elston. All rights reserved. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
