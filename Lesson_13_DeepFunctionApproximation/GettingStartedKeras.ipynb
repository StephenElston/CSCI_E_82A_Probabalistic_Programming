{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Keras\n",
    "\n",
    "## CSCI E-82A\n",
    "## Stephen Elston\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook will provides a first look at using the Keras package to define, train and evaluate deep learning models with Keras. By the end of this lesson you will be able to work with basic feedforward architecture multi-layer neural nets. Feedforward networks are one of a class of basic models called **sequential models** which are easy to define with Keras. Further, some basic regularization is introduced. Additional regularization methods are covered in a subsequent lesson. \n",
    "\n",
    "\n",
    "### 1.1 Installing Keras\n",
    "\n",
    "Keras has recently become part of Tensorflow. Therefore the most straight-forward way to install Keras is by installing Tensorflow first. You can find [installation instructions for Keras](https://keras.io/) for Tensorflow, CNTK and Theano on the Keras web site. Carefully read the limitations and possible pitfalls for you operating system which ever framework you choose. \n",
    "\n",
    "\n",
    "****\n",
    "**Note:** This notebook was constructed and tested using Anaconda 3 with Python 3. It is assumed that the standard Anaconda stack has been installed.\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Keras architecture\n",
    "\n",
    "Keras is a wrapper over other deep learning frameworks. Keras provides consistent and simplified APIs for using these underlying frameworks. In this lesson we will focus on the widely used Python API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Overview of Keras documentation\n",
    "\n",
    "One of the many nice features of Keras is complete and useful documentation. Complete documentation including installation instructions can be found on the [Keras website](https://keras.io/#keras-the-python-deep-learning-library). As you learn to work with Keras, you will want to refer to the well-indexed documentation and examples on this site. \n",
    "\n",
    "A the book [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python) by Fran√ßois Chollet, the creator of Keras, provides in-depth examples and discussion on a wide range of deep learning applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 A first feed-forward Keras example\n",
    "\n",
    "Without further adu, let's try an example. We will build a simple feedforward neural network to classify handwriten digits from the famious MNIST data set. MNIST contains 60,000 labeled training images and 10,000 test images. To many people MNIST is the 'hello world' problem of deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading the MNIST data set\n",
    "\n",
    "MNIST is built intoo the `keras.datasets` package. We only need to import this package and then load it. \n",
    "\n",
    "The first step is to import the packages we will need for the rest of this notebook. Execute the code in the cell below to load these packages. This code should eecute without errors or warnings if everything is installed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import keras.utils.np_utils as ku\n",
    "import keras.models as models\n",
    "import keras.layers as layers\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the TensorFlow backend has been loaded along with various Keras packages. Keras is making calls to TensorFlow to perform compuations.\n",
    "\n",
    "Now, load the training and testing images and corresponding labels by executing the coded in the cell below. . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, let's have a peak at some of the content. The images of the handwritten digits are represented as rectangular arrays of dimension $$28x28$. You can see this by executing the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images[4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handwritten images are all gray-scale, so do not have a color dimension. \n",
    "\n",
    "The code in the cell below displays 4 of the 60,000 images of handwritten digits along with their labels. Execute this code and examine the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 20, 4):\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "    print('Label = ' + str(train_labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Prepare the data for training.\n",
    "\n",
    "As is the case with all machine learning problems, preparing the data is an important step. Without careful data preparation even the best models will produce poor results, or even fail to execute. \n",
    "\n",
    "The MNIST images are stored as a 3-d tensor. For the training data this tensor has dimensions $60000\\ x\\ 28\\ x\\ 28$. However, to traning a neural network on these images we must flatten this representation so that each image is a vector of length $28 * 28$. The result will be a 2-d tensor of dimensions $60000\\ x\\ (28*28)$.\n",
    "\n",
    "Further, models created with Keras, and most other deep learning frameworks, operate on floating point numbers. The gray scale pixel values of the images are coded as integers in the range $\\{ 0, 255 \\}$. These pixel values must be coerced to floating point and then standardized to be in a range $\\{ 0.0, 1.0 \\}$. As is the case for training many machine learning models, it is best to use standardized values for training deep neural networks. \n",
    "\n",
    "The code in the cell below flattens the images and converts the pixel values to a standardized floating point number. Execute this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_images.shape, train_labels.shape)\n",
    "train_images = train_images.reshape((60000, 28*28)).astype('float32')/255\n",
    "print(train_images.shape)\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the original shape and resulting shape of the training image tensor. In addition, the array is now of type `float32`. \n",
    "\n",
    "Execute the code in the cell below to apply the  same transformation to the test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_images.shape, test_labels.shape)\n",
    "test_images = test_images.reshape((10000, 28*28)).astype('float32')/255\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working on a classification problem, the label values must be of a categrocial type. Execute the code in the cell below and examine the coding of  these labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_labels[5:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are coded as integers corresponding to the digit in the image. These values must be coerced to a categorical type. Fortunately the `to_categorical` method in the `keras.utils.np_utils` package does just this. Execute the code in the cell below and examine the printed results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = ku.to_categorical(train_labels)\n",
    "print(train_labels[5:,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label values have been converted from integers to a set of 10 dummy variables. The columns of the dummy variables represent digits in the range $\\{ 0,9 \\}$. One dummy variable per case will be coded as $1$ and the rest coded as $0$. For example the first row in the example above encodes a $2$, and the second row encodes a $1$.\n",
    "\n",
    "Execute the code in the cell below to coerce the test labels to dummy variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = ku.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Defining a sequential model\n",
    "\n",
    "The data is prepared, so it is time to start defining a neural nework model. We are using a simple feedforward model which is one type of sequential model Keras can create. There is a general receipe for defining sequential Keras models:\n",
    "\n",
    "1. Define a sequential model object.\n",
    "2. Define one or more hidden layers.\n",
    "3. Define an output layer. \n",
    "\n",
    "You will find a [quick start guide to Keras sequential models](https://keras.io/getting-started/sequential-model-guide/) in the Keras documentation \n",
    "\n",
    "Speficially in this case, the squential model is defined as follows:\n",
    "1. A sequential model object `nn` is defined. \n",
    "2. A single hidden layer is defined. \n",
    "  - This layer is dense (fully connected) with 512 units. \n",
    "  - The activation of each unit is rectilinear.\n",
    "  - The hidden layer is expecting an input tensor of $28*28$ by an undefined number of cases (images). \n",
    "3. The output layer has 10 hidden units. \n",
    "  - We need 10 units since there are 10 categories of handwritten digits we are classifing. \n",
    "  - This is a **Multinomial** classification problem so we are using softmax activation. \n",
    "  \n",
    "Execute this code to define the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, )))\n",
    "nn.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training and evaluating the sequential model\n",
    "\n",
    "With a defined model it is time to train and evaluate it. First, the model must be compiled by executing the code below. This call sepecifies the following:\n",
    "\n",
    "1. Specify an optimizer. We will discuss optimizers in a subsequent lesson. \n",
    "2. Specify a loss function. In this case we are performing Multinomial classification so we are using `categorical_crossentropy`.\n",
    "3. Specify one or more metrics used to evaluate the performance of the model. In this case we are using just one metric, accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the model is ready to be trained using the `fit` method by executing the code in the cell below. The `fit` method has several arguments:\n",
    "\n",
    "1. The training features.\n",
    "2. The training labels.\n",
    "3. The number of epochs (iterations) over which the model is trained.\n",
    "4. The batch size used for the optimizer. The meaning of this will be discussed in the lesson on optimizaton. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nn.fit(train_images, train_labels, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the loss declines and the accuracy increases with each training epoch. However, since neural networks tend to be overfit, these improved figures may or may not indicate that the model is actually getting better. Keep in mind that the model may simply be learning the training data. \n",
    "\n",
    "It is necessary to test the model on independent data set. The `evaluate` method allows you to do just this. Execute the code in the cell below and compair the results to training results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that the model is over-fit since the evaluation loss and accuracy are quite a bit worse than observed in training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Training over epochs\n",
    "\n",
    "In order to determine at what point a model is overfit during training it is necessary to evaluate the model after each training epoch. \n",
    "\n",
    "The `test_model` function in the cell below iterates the `train` function over increasing numbers of epochs for the model defined. A list of evaluation metrics is created and printed at the end. The test function fits the model for the specified number of epochs and evaluates the result.  \n",
    "\n",
    "If you wish to execute this code uncomment the call in the last line of the cell and run the code. Expect execution to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnt = models.Sequential()\n",
    "nnt.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, )))\n",
    "nnt.add(layers.Dense(10, activation = 'softmax'))\n",
    "nnt.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', \n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "history = nnt.fit(train_images, train_labels, \n",
    "                  epochs = 10, batch_size = 128,\n",
    "                  validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To aid in understanding these figures it will help to make some plots comparing the training and evaluation performance as the training epochs evolve. The code in the next two cells does this is a somewhat primitive manner. The Numpy array is manually edited to include the training loss and training accuracy. \n",
    "\n",
    "The `plot_loss` and `plot_performance` functions in the next two cell plot the training loss or accuracy in blue and the test loss or accuracy in red. Execute the code and examine the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    x = list(range(1, len(test_loss) + 1))\n",
    "    plt.plot(x, test_loss, color = 'red')\n",
    "    plt.plot(x, train_loss)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss vs. Epoch')\n",
    "    \n",
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    train_acc = history.history['acc']\n",
    "    test_acc = history.history['val_acc']\n",
    "    x = list(range(1, len(test_acc) + 1))\n",
    "    plt.plot(x, test_acc, color = 'red')\n",
    "    plt.plot(x, train_acc)  \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs. Epoch')  \n",
    "    \n",
    "plot_accuracy(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training loss and accuracy continue to improve throughout the epochs. However, the evaluation loss and accuracy only improve significantly for the first four, or perhaps 5, epochs. This is clear evidence that subsequent epochs are simply over-fitting the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Adding hidden layers\n",
    "\n",
    "Next, we will add an additional hidden layer to the model. Addiional layers add capacity to the model to represent complex function. However, the network becomes more susceptible to over fitting. \n",
    "\n",
    "The code in the cell below defines a model similar to the first one, but with a second layer defined. Notice that the definition of the two layer model is nearly the same as for the single layer model. In this case, the second layer has the same number of units and activation function as the first. \n",
    "\n",
    "However, notice that the `input_shape` does not need to be defined for hidden layers past the first. Keras will determine the dimensions of tensors passed between layers past the input. \n",
    "\n",
    "If you wish to execute this code uncomment the call in the last line of the cell and run the code. Expect execution to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnt = models.Sequential()\n",
    "nnt.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, )))\n",
    "nnt.add(layers.Dense(512, activation = 'relu'))\n",
    "nnt.add(layers.Dense(10, activation = 'softmax'))\n",
    "nnt.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', \n",
    "                metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "history = nnt.fit(train_images, train_labels, \n",
    "                  epochs = 10, batch_size = 128,\n",
    "                  validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can best understand these results by creating plots of the loss and accuracy for training and evaluation vs. epoch. Execute the code in the two cells below to display these plots and study the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that after epoch four the true (training) loss actually increases, whereas the training loss continues to decrease. This is a clear indication of overfitting. \n",
    "\n",
    "When compared to the single layer example, the over-fitting is more obvious. This should not be a suprise, since the number of weights has nearly doubled from the single layer model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Adding regularization to the model\n",
    "\n",
    "Regularization is used to prevent over-fitting of machine learning models including neural networks. The Keras `regularizers` package provides L1 and L2 regularizaiton methods. The theory of regularization will be addressed in other lessons. In addition you can find [documentation on the Keras `regularizers` package](https://keras.io/regularizers/).  \n",
    "\n",
    "The code in the cell below adds the `kernel_regularizer` argument with the value of `regularizers.l2(0.01)` This adds a weight decay penalty of 0.01 to the model weights. \n",
    "\n",
    "If you wish to execute this code uncomment the call in the last line of the cell and run the code. Expect execution to take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nnt = models.Sequential()\n",
    "nnt.add(layers.Dense(512, activation = 'relu', input_shape = (28*28, ),\n",
    "                        kernel_regularizer=regularizers.l2(0.01)))#\n",
    "nnt.add(layers.Dense(10, activation = 'softmax'))\n",
    "nnt.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    \n",
    "history = nnt.fit(train_images, train_labels, \n",
    "                  epochs = 10, batch_size = 128,\n",
    "                  validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can best understand these results by creating plots of the loss and accuracy for training and evaluation vs. epoch. Execute the code in the two cells below to display these plots and study the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss(history)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_accuracy(history)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to the pervious two models. \n",
    "\n",
    "First, notice that the loss values are significantly higher and the accuracy lower. This is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Copyright 2018, Stephen F Elston. All rights reserved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
